<!doctype html>
<html class="no-js" lang="en">

<head>
    <script id="dpal" src="//www.redhat.com/ma/dpal.js" type="text/javascript"></script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="shortcut icon" type="image/png" href="/favicon.png">
    <meta name="theme-color" content="#008585">
    
    <title>Deploying OCI Container Images to Bare Metal with a Custom IPA Hardware Manager | Metal³ - Metal Kubed</title>
    <!-- # Opengraph protocol properties: https://ogp.me/ -->
    <meta name="author" content="Serhii Ivanov" >
    <meta property="og:type" content="article" >
    <meta name="twitter:card" content="summary">
    <meta name="description" content="Metal3.io aims to build on baremetal host provisioning technologies to provide a Kubernetes native API for managing bare metal hosts via a provisioning stack that is also running on Kubernetes.">
    <meta name="keywords" content="metal3, ironic, IPA, OCI, deployment, bare metal" >
    <meta property="og:title" content="Deploying OCI Container Images to Bare Metal with a Custom IPA Hardware Manager | Metal³ - Metal Kubed">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://metal3.io/blog/2026/02/01/Deploying_OCI_Images_with_Custom_IPA_Hardware_Manager.html" >
    <meta property="og:image" content="https://metal3.io/assets/images/metal3logo.png">
    <meta property="og:description" content="Metal3.io aims to build on baremetal host provisioning technologies to provide a Kubernetes native API for managing bare metal hosts via a provisioning stack that is also running on Kubernetes." >
    <meta property="og:site_name" content="Metal³ - Metal Kubed" >
    <meta property="og:article:author" content="Serhii Ivanov" >
    <meta property="og:article:published_time" content="2026-02-01 00:00:00 -0600" >
    <meta name="twitter:title" content="Deploying OCI Container Images to Bare Metal with a Custom IPA Hardware Manager | Metal³ - Metal Kubed">
    <meta name="twitter:description" content="Metal3.io aims to build on baremetal host provisioning technologies to provide a Kubernetes native API for managing bare metal hosts via a provisioning stack that is also running on Kubernetes.">

    <link type="application/atom+xml" rel="alternate" href="https://metal3.io/feed.xml" title="Metal³ - Metal Kubed" />
    <meta name="google-site-verification" content="HCdbGknTOCTKQVt7m-VxTG4BEYXxSqm-sDb-iklqrB0" />
  <link href="https://fonts.googleapis.com/css?family=Nunito:200,400&display=swap" rel="stylesheet">
  <script defer src="https://use.fontawesome.com/releases/v5.1.0/js/all.js" integrity="sha384-3LK/3kTpDE/Pkp8gTNp2gR/2gOiwQ6QaO7Td0zV76UFJVhqLl4Vl3KL1We6q6wR9" crossorigin="anonymous"></script>
  <!-- Photoswipe.com gallery-->

  <!-- Core CSS file -->
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.3/photoswipe.min.css">

  <!-- Skin CSS file (styling of UI - buttons, caption, etc.)
      In the folder of skin CSS file there are also:
      - .png and .svg icons sprite,
      - preloader.gif (for browsers that do not support CSS animations) -->
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.3/default-skin/default-skin.min.css">
</head>
<body>
    <!--[if IE]>
      <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
    <![endif]-->

<div class="mk-wrapper">
    <section class="mk-masthead mk-masthead--sub">
<header class="mk-main-header">
    <a href="/" class="mk-main-header__brand">
        <svg version="1.1" viewBox="0 0 557 540" xmlns="http://www.w3.org/2000/svg">
          <g fill="none" fill-rule="evenodd">
            <g transform="translate(-1)" fill-rule="nonzero">
            <path d="m181.91 539.68h-0.7c-0.76 0-1.44-0.11-2-0.17h-0.14l-1.62-0.2c-15.204-1.867-29.364-8.7129-40.27-19.47l-1.07-1.06-49.46-61.26-73.34-90.59-0.5-0.72c-2.8927-4.0899-5.2989-8.503-7.17-13.15-1.0257-2.532-1.8875-5.1274-2.58-7.77v-0.11c-0.22-0.85-0.43-1.69-0.62-2.56v-0.14c-0.8042-3.5966-1.2861-7.2578-1.44-10.94v-0.47-0.48c-0.067687-4.136 0.26722-8.2688 1-12.34l0.11-0.61 14.51-63.64 28.72-126c4.0017-17.442 15.802-32.074 32-39.68l178.2-85.93 3.34-0.67c5.6926-1.1418 11.484-1.7201 17.29-1.7201h2.83 0.57c8.4518-0.016309 16.808 1.7879 24.5 5.2901l0.47 0.22 175.82 84.2 0.48 0.25c7.1101 3.7526 13.491 8.7481 18.84 14.75 2.7886 3.1018 5.2639 6.4715 7.39 10.06l0.17 0.29c2.1776 3.7964 3.9314 7.8205 5.23 12l0.3 1 44.23 190.25 0.17 1.42c2.0399 16.443-2.1677 33.052-11.79 46.54l-0.48 0.68-121.46 150.24c-7.2792 9.604-17.475 16.59-29.06 19.91-0.93 0.27-1.87 0.52-2.81 0.75l-0.3 0.07c-5.0328 1.1701-10.183 1.76-15.35 1.76h-194.01z" fill="#fff"/>
            <path d="m492 131.65c-0.75221-2.3458-1.7582-4.6025-3-6.73-1.2507-2.1148-2.7114-4.0982-4.36-5.92-3.3032-3.7145-7.2456-6.8067-11.64-9.13l-179.82-86c-4.3569-1.9816-9.0938-2.9883-13.88-2.95h-0.77c-4.9428-0.19294-9.8909 0.20318-14.74 1.18l-179.72 86.6c-8.9642 4.1124-15.498 12.17-17.67 21.79l-3.69 16.16 216.29 117.67 0.34-0.18 217.22-112.72-4.56-19.77z" fill="#00E0C1"/>
            <path d="m279 264.32l-216.29-117.67-25.77 113.1-14.73 64.63c-0.44744 2.4671-0.64178 4.9734-0.58 7.48v0.29c0.072639 2.1493 0.33702 4.2878 0.79 6.39 0.12 0.56 0.26 1.1 0.4 1.65 0.41228 1.5719 0.92671 3.1151 1.54 4.62 1.1152 2.7748 2.5517 5.4095 4.28 7.85l23.69 29.27 51 63 49.67 61.55c6.7982 6.7311 15.643 11.009 25.14 12.16 0.67 0 1.31 0.18 2 0.21h99.17v-254.34l-0.31-0.19z" fill="#00EEC4"/>
            <path d="m536.75 324.38l-40.19-173-217.23 112.76v254.71h98.82c3.2616 0.017 6.5139-0.34884 9.69-1.0906 0.62-0.15 1.23-0.31 1.84-0.49 6.2438-1.7629 11.72-5.5604 15.56-10.79l66.09-81.75 31.31-38.73 26.94-33.33c5.8432-8.2018 8.4013-18.295 7.17-28.29z" fill="#00D1BD"/>
            <path d="m120.94 369l137 75.89c1.3702 0.76284 3.0421 0.74251 4.3933-0.05344s2.1796-2.2483 2.1767-3.8166v-161.02c0-5.718-3.1489-10.971-8.19-13.67l-1.64-0.87-134.68-71.99c-0.8041-0.43178-1.7757-0.41032-2.56 0.056543-0.78426 0.46687-1.2663 1.3108-1.27 2.2235l-0.94 163.17c0.02 3.63 2.77 8.44 5.71 10.08z" fill="#fff"/>
            <path d="m282.61 103.85c-4.0372-0.033083-8.0333 0.81323-11.71 2.481l-134.2 60.47c-0.91184 0.40637-1.512 1.2973-1.5476 2.295-0.032512 0.99771 0.50554 1.9274 1.3876 2.395l135.72 72.51c0.15 0.09 0.31 0.16 0.47 0.24l0.59 0.29 0.26 0.11 0.8 0.34h0.09c4.9879 1.8704 10.539 1.5061 15.24-1l139.14-73.94c1.1079-0.5822 1.7814-1.7504 1.7328-3.0009-0.054039-1.2505-0.82096-2.3596-1.9728-2.8491l-135.06-58.05c-3.4545-1.4945-7.1761-2.2735-10.94-2.291z" fill="#fff"/>
            <path d="m442.82 192.61c-1.08-0.49333-2.4133-0.29667-4 0.59l-24.52 13.54c-3.6117 1.9922-6.3845 5.2194-7.81 9.09l-37.49 87.55-37.31-46.2c-1.59-2.29-4.2-2.45-7.81-0.45l-24.51 13.54c-1.6358 0.9266-3.0116 2.2508-4 3.85-1.0039 1.4454-1.5667 3.151-1.62 4.91v166.83c0 1.59 0.55 2.59 1.63 3s2.42 0.19 4-0.69l27.34-15.1c1.6143-0.90735 2.9864-2.1902 4-3.74 1.0178-1.3976 1.5863-3.0717 1.63-4.8v-105l23.21 30.12c2.1667 2.1267 4.6967 2.3933 7.59 0.8l11.67-6.45c3.18-1.7467 5.71-4.8067 7.59-9.18l23.43-55.9 0.25 97.1 0.17 8.31c-0.10795 1.217 0.57186 2.3675 1.69 2.86 1.2747 0.44018 2.6836 0.23517 3.78-0.55l27.27-15.83c1.5869-0.9387 2.9245-2.2455 3.9-3.81 0.9881-1.4207 1.5184-3.1095 1.5212-4.84v-166.43c0.028815-1.6-0.51118-2.64-1.6012-3.12z" fill="#fff"/>
            </g>
          </g>
        </svg>
      </a>
      <div role="navigation" class="mk-main-header__nav-wrapper">
        <button class="mk-main-header__toggle" id="toggle" aria-controls="main_nav" aria-expanded="false" aria-label="navigation toggle" >
          <svg version="1.1" viewBox="0 0 512 448" xmlns="http://www.w3.org/2000/svg">
          <g>
          <path d="m296 0h192c13.255 0 24 10.745 24 24v160c0 13.255-10.745 24-24 24h-192c-13.255 0-24-10.745-24-24v-160c0-13.255 10.745-24 24-24zm-80 0h-192c-13.255 0-24 10.745-24 24v160c0 13.255 10.745 24 24 24h192c13.255 0 24-10.745 24-24v-160c0-13.255-10.745-24-24-24zm-216 264v160c0 13.255 10.745 24 24 24h192c13.255 0 24-10.745 24-24v-160c0-13.255-10.745-24-24-24h-192c-13.255 0-24 10.745-24 24zm296 184h192c13.255 0 24-10.745 24-24v-160c0-13.255-10.745-24-24-24h-192c-13.255 0-24 10.745-24 24v160c0 13.255 10.745 24 24 24z"/>
          </g>
          </svg>
          <span class="mk-main-header__toggle-text">menu</span>
        </button>
        </div>
        <ul id="main_nav" class="mk-main-nav">
          <li ><a class="mk-main-nav__item" href="/blog/index.html">Blog</a></li>
          <li ><a class="mk-main-nav__item" href="/community-resources.html">Community Resources</a></li>
          <li ><a class="mk-main-nav__item" href="https://book.metal3.io">Documentation</a></li>
          <li ><a class="mk-main-nav__item" href="/contribute.html">Contribute</a></li>
          <li ><a class="mk-main-nav__item" href="/faqs.html">FAQs</a></li>
          <li ><a class="mk-main-nav__item" href="https://book.metal3.io/developer_environment/tryit">Try It!</a></li>
          <li  id="mk-main-nav__search">
            <form action="/search.html" method="get" autocomplete="off" class="mk-search-form">
              <div class="autocomplete" style="width:150px;">
                <input type="text" id="search-input" class="docs-search--input" placeholder="Search Term" name="query">
              </div>
              <button type="submit" id = "search-button" class = "search-button" disabled = 'true' >
                <img src="/assets/images/search.png" style="height: 20px;" alt="">
              </button>
                <div id="mode-toggle">
                  <img src="/assets/images/moon-outline.png" id="mode-icon" style="height: 20px; margin-left: 10px;"/>
                </div>
            </form>
          </li>

        </ul>
  </header>
  
<script>
function autocomplete(inp, arr) {
  /*the autocomplete function takes two arguments,
  the text field element and an array of possible autocompleted values:*/
  var currentFocus;
  /*execute a function when someone writes in the text field:*/
  inp.addEventListener("input", function(e) {
      var a, b, i, val = this.value;
      /*close any already open lists of autocompleted values*/
      closeAllLists();
      if (!val) { return false;}
      currentFocus = -1;
      /*create a DIV element that will contain the items (values):*/
      a = document.createElement("DIV");
      a.setAttribute("id", this.id + "autocomplete-list");
      a.setAttribute("class", "autocomplete-items");
      /*append the DIV element as a child of the autocomplete container:*/
      this.parentNode.appendChild(a);
      /*for each item in the array...*/
      for (i = 0; i < arr.length; i++) {
        /*check if the item starts with the same letters as the text field value:*/
        if (arr[i].substr(0, val.length).toUpperCase() == val.toUpperCase()) {
          /*create a DIV element for each matching element:*/
          b = document.createElement("DIV");
          /*make the matching letters bold:*/
          b.innerHTML = "<strong>" + arr[i].substr(0, val.length) + "</strong>";
          b.innerHTML += arr[i].substr(val.length);
          /*insert a input field that will hold the current array item's value:*/
          b.innerHTML += "<input type='hidden' value='" + arr[i] + "'>";
          /*execute a function when someone clicks on the item value (DIV element):*/
              b.addEventListener("click", function(e) {
              /*insert the value for the autocomplete text field:*/
              inp.value = this.getElementsByTagName("input")[0].value;
              /*close the list of autocompleted values,
              (or any other open lists of autocompleted values:*/
              closeAllLists();
          });
          a.appendChild(b);
        }
      }
  });
  /*execute a function presses a key on the keyboard:*/
  inp.addEventListener("keydown", function(e) {
      document.getElementById("search-button").disabled= undefined;
      var x = document.getElementById(this.id + "autocomplete-list");
      if (x) x = x.getElementsByTagName("div");
      if (e.keyCode == 40) {
        /*If the arrow DOWN key is pressed,
        increase the currentFocus variable:*/
        currentFocus++;
        /*and and make the current item more visible:*/
        addActive(x);
      } else if (e.keyCode == 38) { //up
        /*If the arrow UP key is pressed,
        decrease the currentFocus variable:*/
        currentFocus--;
        /*and and make the current item more visible:*/
        addActive(x);
      } else if (e.keyCode == 13) {
        /*If the ENTER key is pressed, prevent the form from being submitted,*/
        if (currentFocus > -1) {
          /*and simulate a click on the "active" item:*/
          if (x) {
            x[currentFocus].click();
            e.preventDefault();
          }
        }
        if (document.getElementById("search-input").value == "") {
          e.preventDefault();
        }
      }
  });
  function addActive(x) {
    /*a function to classify an item as "active":*/
    if (!x) return false;
    /*start by removing the "active" class on all items:*/
    removeActive(x);
    if (currentFocus >= x.length) currentFocus = 0;
    if (currentFocus < 0) currentFocus = (x.length - 1);
    /*add class "autocomplete-active":*/
    x[currentFocus].classList.add("autocomplete-active");
  }
  function removeActive(x) {
    /*a function to remove the "active" class from all autocomplete items:*/
    for (var i = 0; i < x.length; i++) {
      x[i].classList.remove("autocomplete-active");
    }
  }
  function closeAllLists(elmnt) {
    /*close all autocomplete lists in the document,
    except the one passed as an argument:*/
    var x = document.getElementsByClassName("autocomplete-items");
    for (var i = 0; i < x.length; i++) {
      if (elmnt != x[i] && elmnt != inp) {
      x[i].parentNode.removeChild(x[i]);
    }
  }
}
/*execute a function when someone clicks in the document:*/
document.addEventListener("click", function (e) {
    closeAllLists(e.target);
});
}
</script>
<script>
  document.addEventListener("DOMContentLoaded", function(){
  let iconMode = document.getElementById("mode-icon")
  let toggleMode = document.getElementById("mode-toggle")
  let cncfImage = document.getElementById("cncf-image")
let isToggled = localStorage.getItem("currentMode") === "true";
updateMode();
toggleMode.addEventListener("click", () => {
  isToggled = !isToggled;
  localStorage.setItem("currentMode", isToggled);
  updateMode();
});
function updateMode() {
  let mastHead = document.querySelector(".mk-masthead");
  let h1 = document.querySelectorAll("h1")
  let h2 = document.querySelectorAll("h2")
  let h3 = document.querySelectorAll("h3")
  let li = document.querySelectorAll("li")
  let sections = document.querySelectorAll(".mk-main__section")
  let body = document.querySelector("body")
  let whyCards = document.querySelectorAll(".mk-why-baremetal__card")
  let blogCards = document.querySelectorAll(".mk-blog-meta__card")
  let questions = document.querySelectorAll(".mk-faqs__question")
  let subHeadings = document.querySelectorAll(".mk-sub-heading")
  let p = document.querySelectorAll("p")
  if (isToggled) {

    iconMode.src = "/assets/images/moon-outline.png";
    cncfImage.src = "/assets/images/cncf-white.svg";
    mastHead.style.backgroundColor = "var(--mk--BackgroundColor--500)";
    body.style.backgroundColor = "var(--mk--BackgroundColor--500)";
    body.style.color = "var(--mk--Color--200)";
    h1.forEach((eachH1)=>{
      eachH1.style.color = "var(--mk--Color--200)"
    })
    h2.forEach((eachH2)=>{
      eachH2.style.color = "var(--mk--Color--200)"
    })
    h3.forEach((eachH3)=>{
      eachH3.style.color = "var(--mk--Color--200)"
    })
    li.forEach((eachLi)=>{
      eachLi.style.color = "var(--mk--Color--200)"
    })
    sections.forEach((section)=>{
      section.style.backgroundColor = "var(--mk--BackgroundColor--500)";
    })
    p.forEach((eachP)=>{
      eachP.style.color = "var(--mk--Color--200)"
    })
    whyCards.forEach((whyCard)=>{
    whyCard.querySelector("h3").style.color = "var(--mk--BackgroundColor--150)"
      whyCard.style.backgroundColor = "var(--mk--BackgroundColor--175)"
    })
    blogCards.forEach((blogCard)=>{
      blogCard.style.backgroundColor = "var(--mk--color-brand--400)";
    })
    questions.forEach((question)=>{
      question.style.color = "var(--mk--Color--200)"
    })
    subHeadings.forEach((subHeading)=>{
      subHeading.style.color = "var(--mk--Color--500)"
    })
  } else {
    iconMode.src = "/assets/images/moon.png";
    cncfImage.src = "/assets/images/cncf-color.svg";
    mastHead.style.backgroundColor = "";
    body.style.backgroundColor = "";
    body.style.color = "var(--mk--Color--400)";


    h1.forEach((eachH1)=>{
      eachH1.style.color = ""
    })
    h2.forEach((eachH2)=>{
      eachH2.style.color = ""
    })
    h3.forEach((eachH3)=>{
      eachH3.style.color = ""
    })
    sections.forEach((section)=>{
      section.style.backgroundColor = "var(--mk--BackgroundColor--250)";
    })
    li.forEach((eachLi)=>{
      eachLi.style.color = ""
    })
    p.forEach((eachP)=>{
      eachP.style.color = ""
    })
    whyCards.forEach((whyCard)=>{
      whyCard.querySelector("h3").style.color = ""
      whyCard.style.backgroundColor = "white"
    })
    blogCards.forEach((blogCard)=>{
      blogCard.style.backgroundColor = ""
    })
    questions.forEach((question)=>{
      question.style.color = ""
    })
    subHeadings.forEach((subHeading)=>{
      subHeading.style.color = "var(--mk--Color--500)"
    })


  }
}
})
</script>
<script>
var mykeywords = ["hybrid", "cloud", "metal3", "baremetal", "stack", "edge", "openstack", "ironic", "openshift", "kubernetes", "OpenStack", "operator", "summit", "kubecon", "shiftdev", "metal3-dev-env", "documentation", "development", "talk", "conference", "meetup", "cluster API", "provider", "raw image", "image streaming", "IPAM", "ip address manager", "Pivoting", "Move", "scaling", "cncf", "community", "announcement", "IPA", "OCI", "deployment", "bare metal", ]
autocomplete(document.getElementById("search-input"), mykeywords);
</script>
<script src="/assets/js/clipboard.min.js"></script>
<!-- Photoswipe -->
<!-- Core JS file -->
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.3/photoswipe.min.js"></script>
<!-- UI JS file -->
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<div class="mk-masthead__content--sub">
        <h1 class="mk-masthead__content--sub__title">Blog</h1>
        <p class="mk-masthead__content--sub__text">Read about the newest updates in the community.</p>
</div>
</section>
<main class="mk-main mk-blog">
            <article class="mk-main__section mk-main__content mk-main__section__content">
                    <h1 class="mk-heading--lg mk-heading mk-m-border mk-blog__post__title">Deploying OCI Container Images to Bare Metal with a Custom IPA Hardware Manager</h1>
                    <time datetime="1999-12-23" class="mk-blog-meta__timestamp mk-blog-meta__item mk-blog-meta__timestamp--light">Sunday, 1/02/2026</time>
                    <div class="mk-blog-meta__item mk-blog-meta__author">By Serhii Ivanov</div>
                    <div class="mk-blog-meta__categories">
                                
                                <a class="mk-blog-meta__item mk-blog-meta__category" href="/blog/categories.html#metal3">
                                  metal3
                                </a>
                              
                                <a class="mk-blog-meta__item mk-blog-meta__category" href="/blog/categories.html#ironic">
                                  ironic
                                </a>
                              
                                <a class="mk-blog-meta__item mk-blog-meta__category" href="/blog/categories.html#ipa">
                                  ipa
                                </a>
                              
                                <a class="mk-blog-meta__item mk-blog-meta__category" href="/blog/categories.html#oci">
                                  oci
                                </a>
                              
                                <a class="mk-blog-meta__item mk-blog-meta__category" href="/blog/categories.html#deployment">
                                  deployment
                                </a>
                              
                                <a class="mk-blog-meta__item mk-blog-meta__category" href="/blog/categories.html#bare-metal">
                                  bare-metal
                                </a>
                              
                </div>

<div class="mk-share-buttons">

           <!-- <a class="mk-share-buttons__item" href="https://www.facebook.com/sharer/sharer.php?u=https://metal3.io/blog/2026/02/01/Deploying_OCI_Images_with_Custom_IPA_Hardware_Manager.html"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Facebook" >
            <?xml version="1.0" encoding="UTF-8"?>
<svg enable-background="new 0 0 1024 1024" version="1.1" viewBox="0 0 1024 1024" xml:space="preserve" xmlns="http://www.w3.org/2000/svg">
	<path d="M1024,512C1024,229.2,794.8,0,512,0S0,229.2,0,512c0,255.6,187.2,467.4,432,505.8V660H302V512h130V399.2   C432,270.9,508.4,200,625.4,200c56,0,114.6,10,114.6,10v126h-64.6c-63.6,0-83.4,39.5-83.4,80v96h142l-22.7,148H592v357.8   C836.8,979.4,1024,767.6,1024,512z"/>
	<path class="st0" d="M711.3,660L734,512H592v-96c0-40.5,19.8-80,83.4-80H740V210c0,0-58.6-10-114.6-10   c-117,0-193.4,70.9-193.4,199.2V512H302v148h130v357.8c26.1,4.1,52.8,6.2,80,6.2s53.9-2.1,80-6.2V660H711.3z"/>
</svg>Share on Facebook</a> -->


        <a class="mk-share-buttons__item" href="https://twitter.com/intent/tweet?text=Deploying OCI Container Images to Bare Metal with a Custom IPA Hardware Manager&url=https://metal3.io/blog/2026/02/01/Deploying_OCI_Images_with_Custom_IPA_Hardware_Manager.html"
        onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
        title="Share on Twitter" >
        <?xml version="1.0" encoding="UTF-8"?>
<svg enable-background="new 0 0 250 203.1" version="1.1" viewBox="0 0 250 203.1" xml:space="preserve" xmlns="http://www.w3.org/2000/svg">
<path class="st1" d="m78.6 203.1c94.3 0 145.9-78.2 145.9-145.9 0-2.2 0-4.4-0.1-6.6 10-7.3 18.7-16.3 25.6-26.5-9.4 4.1-19.3 6.9-29.5 8.1 10.7-6.4 18.7-16.5 22.5-28.4-10.1 6-21.1 10.2-32.6 12.4-19.4-20.7-51.9-21.7-72.6-2.2-13.3 12.5-19 31.2-14.8 49-41.1-2.1-79.6-21.6-105.6-53.6-13.6 23.4-6.7 53.4 15.9 68.4-8.2-0.2-16.1-2.4-23.3-6.4v0.6c0 24.4 17.2 45.4 41.2 50.3-7.6 2.1-15.5 2.4-23.2 0.9 6.7 20.9 26 35.2 47.9 35.6-18.2 14.3-40.6 22-63.7 22-4.1 0-8.2-0.3-12.2-0.7 23.5 15.1 50.7 23 78.6 23"/>
</svg> Share on Twitter
    </a>
</div>
        <p>What if you could deploy any OCI container image directly to bare metal,
without building traditional disk images? Back in 2021, Dmitry Tantsur
<a href="https://owlet.today/posts/integrating-coreos-installer-with-ironic/">implemented custom deploy steps</a>
for Ironic, enabling alternative deployment methods beyond the standard
image-based approach. This feature powers OpenShift’s bare metal
provisioning with CoreOS, yet it remains surprisingly unknown to the
broader Metal3 community. This post aims to change that by providing an
example implementation of a custom IPA hardware manager that deploys
Debian-based container images with EFI boot, LVM root filesystem, and
optional RAID1 mirroring.</p>

<h2 id="the-problem-with-traditional-image-based-deployments">The Problem with Traditional Image-Based Deployments</h2>

<p>Traditional bare metal provisioning with Metal3 and Ironic typically
requires pre-built disk images. You need to maintain these images,
update them regularly, and ensure they contain all necessary drivers
and configurations. This approach has some drawbacks:</p>

<ol>
  <li><strong>Image building complexity</strong> - Building and maintaining OS disk
images is not as trivial as creating container images</li>
  <li><strong>Software RAID limitations</strong> - Image-based deployments with mdadm
RAID and EFI boot require workarounds</li>
</ol>

<p>What if we could leverage the container ecosystem instead? Container
registries already solve the distribution problem, and OCI images are
versioned, layered, simple to build and widely available. This approach
allows you to:</p>

<ul>
  <li>Use standard container images from any registry</li>
  <li>Avoid maintaining custom disk images</li>
  <li>Easily switch between OS versions by updating <code class="language-plaintext highlighter-rouge">spec.image.url</code></li>
  <li>Get RAID1 redundancy with minimal configuration</li>
</ul>

<h2 id="introducing-the-deb_oci_efi_lvm-hardware-manager">Introducing the deb_oci_efi_lvm Hardware Manager</h2>

<p>The <a href="https://github.com/s3rj1k/ironic-python-agent/blob/custom_deploy/ironic_python_agent/hardware_managers/deb_oci_efi_lvm.py"><code class="language-plaintext highlighter-rouge">DebOCIEFILVMHardwareManager</code></a>
is a custom IPA hardware manager that deploys Debian-based OCI container
images directly to bare metal. It
provides:</p>

<ul>
  <li><strong>EFI boot support</strong> - UEFI boot with GRUB, which unlike systemd-boot,
supports booting from LVM on top of mdadm software RAID</li>
  <li><strong>LVM root filesystem</strong> - Flexible volume management for the root
partition</li>
  <li><strong>Optional RAID1</strong> - Software mirroring across two disks for
redundancy</li>
  <li><strong>Cloud-init integration</strong> - Ironic <a href="https://book.metal3.io/bmo/instance_customization.html#implementation-notes">configdrive</a>
data is written directly to the root filesystem, no separate configdrive
partition</li>
  <li><strong>Multi-architecture</strong> - Supports x86_64 and ARM64 via OCI multi-arch
images</li>
</ul>

<h2 id="how-it-works">How It Works</h2>

<p>The deployment process extracts an OCI image using Google’s <code class="language-plaintext highlighter-rouge">crane</code> tool,
then installs the necessary boot infrastructure on top. The hardware
manager supports three methods for specifying the OCI image (in priority
order):</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">spec.image.url</code> with <code class="language-plaintext highlighter-rouge">oci://</code> prefix (e.g., <code class="language-plaintext highlighter-rouge">oci://debian:12</code>)</li>
  <li>Configdrive metadata annotation <code class="language-plaintext highlighter-rouge">bmh.metal3.io/oci_image</code></li>
  <li>Default fallback: <code class="language-plaintext highlighter-rouge">ubuntu:24.04</code></li>
</ol>

<p>Root device hints can be specified using either standard BareMetalHost
<code class="language-plaintext highlighter-rouge">rootDeviceHints</code> fields or a simplified format via the
<code class="language-plaintext highlighter-rouge">bmh.metal3.io/root_device_hints</code> annotation (e.g., <code class="language-plaintext highlighter-rouge">serial=ABC123</code> or
<code class="language-plaintext highlighter-rouge">wwn=0x123456</code>). For RAID1 configurations, provide two space-separated
values (e.g., <code class="language-plaintext highlighter-rouge">serial=ABC123 DEF456</code>).</p>

<blockquote>
  <p><strong>Note:</strong> Alternatively, <code class="language-plaintext highlighter-rouge">podman</code> can be used instead of <code class="language-plaintext highlighter-rouge">crane</code> for OCI
image extraction, as it is readily available in CentOS Stream 9 and also
has an export command. This would require code modifications to the
hardware manager.</p>
</blockquote>

<p>The hardware manager performs these steps during deployment:</p>

<ol>
  <li><strong>Resolve OCI image</strong> - Check <code class="language-plaintext highlighter-rouge">image_source</code>, configdrive, or use default</li>
  <li><strong>Resolve target disks</strong> - Parse root device hints (serial or WWN)</li>
  <li><strong>Clean existing data</strong> - Wipe partitions, RAID arrays, and LVM based on
disk wipe mode (<code class="language-plaintext highlighter-rouge">all</code> for RAID1, <code class="language-plaintext highlighter-rouge">target</code> for single disk by default)</li>
  <li><strong>Partition disks</strong> - Create 2GB EFI partition and LVM partition
(with RAID1 if two disks are specified)</li>
  <li><strong>Create filesystems</strong> - FAT32 for EFI, ext4 for root LV</li>
  <li><strong>Extract OCI image</strong> - Use <code class="language-plaintext highlighter-rouge">crane export</code> piped to <code class="language-plaintext highlighter-rouge">tar</code> for rootfs</li>
  <li><strong>Install packages</strong> - Add cloud-init, GRUB, kernel, mdadm, lvm2</li>
  <li><strong>Configure boot</strong> - Set up GRUB, initramfs, and fstab</li>
  <li><strong>Install bootloader</strong> - GRUB to both EFI partitions for RAID1</li>
</ol>

<h3 id="disk-layout">Disk Layout</h3>

<p>The hardware manager creates the following partition layout:</p>

<table>
  <thead>
    <tr>
      <th>Partition</th>
      <th>Size</th>
      <th>Filesystem</th>
      <th>Label</th>
      <th>Mount Point</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1 (EFI)</td>
      <td>2 GB</td>
      <td>FAT32</td>
      <td>EFI</td>
      <td>/boot/efi</td>
    </tr>
    <tr>
      <td>2 (LVM/RAID)</td>
      <td>Remaining</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
    </tr>
  </tbody>
</table>

<p>The LVM configuration:</p>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Name</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Volume Group</td>
      <td>vg_root</td>
      <td>Contains all logical volumes</td>
    </tr>
    <tr>
      <td>Logical Volume</td>
      <td>lv_root</td>
      <td>Root filesystem (100% of VG)</td>
    </tr>
    <tr>
      <td>Filesystem</td>
      <td>ext4</td>
      <td>Label: ROOTFS</td>
    </tr>
  </tbody>
</table>

<p>For RAID1 configurations, both disks get identical partition tables,
with partition 2 forming a RAID1 array that serves as the LVM physical
volume.</p>

<h2 id="configuration">Configuration</h2>

<h3 id="basic-single-disk-deployment">Basic Single-Disk Deployment</h3>

<p>For a simple single-disk deployment, configure your BareMetalHost and
Metal3MachineTemplate as follows:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">metal3.io/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">BareMetalHost</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-server</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">metal3</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">online</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">bootMode</span><span class="pi">:</span> <span class="s">UEFI</span>
  <span class="c1"># Preferred method: Use spec.image.url with oci:// prefix</span>
  <span class="na">image</span><span class="pi">:</span>
    <span class="na">url</span><span class="pi">:</span> <span class="s2">"</span><span class="s">oci://debian:12"</span>
  <span class="na">rootDeviceHints</span><span class="pi">:</span>
    <span class="na">serialNumber</span><span class="pi">:</span> <span class="s2">"</span><span class="s">DISK_SERIAL_NUMBER"</span>
</code></pre></div></div>

<p>Alternatively, you can use annotations or simplified hint formats:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">metal3.io/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">BareMetalHost</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-server-alt</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">metal3</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="c1"># Alternative: Override default ubuntu:24.04 via annotation</span>
    <span class="na">bmh.metal3.io/oci_image</span><span class="pi">:</span> <span class="s2">"</span><span class="s">debian:12"</span>
    <span class="c1"># Alternative: Use simplified hint format</span>
    <span class="na">bmh.metal3.io/root_device_hints</span><span class="pi">:</span> <span class="s2">"</span><span class="s">serial=DISK_SERIAL_NUMBER"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">online</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">bootMode</span><span class="pi">:</span> <span class="s">UEFI</span>
</code></pre></div></div>

<p>The hardware manager supports three methods for specifying the OCI image
(in priority order):</p>

<ol>
  <li><strong>spec.image.url</strong> with <code class="language-plaintext highlighter-rouge">oci://</code> prefix (highest priority, recommended)</li>
  <li><strong>Annotation</strong> <code class="language-plaintext highlighter-rouge">bmh.metal3.io/oci_image</code> passed via Metal3DataTemplate</li>
  <li><strong>Default</strong> <code class="language-plaintext highlighter-rouge">ubuntu:24.04</code> (fallback)</li>
</ol>

<p>Root device hints support both standard format (<code class="language-plaintext highlighter-rouge">serialNumber: "ABC123"</code>)
and simplified format via annotation (<code class="language-plaintext highlighter-rouge">bmh.metal3.io/root_device_hints: "serial=ABC123"</code>).</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">infrastructure.cluster.x-k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Metal3MachineTemplate</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-worker-template</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">metal3</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">customDeploy</span><span class="pi">:</span>
        <span class="na">method</span><span class="pi">:</span> <span class="s2">"</span><span class="s">deb_oci_efi_lvm"</span>
      <span class="na">dataTemplate</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">my-data-template</span>
</code></pre></div></div>

<h3 id="raid1-configuration">RAID1 Configuration</h3>

<p>For production deployments requiring disk redundancy, specify two disk
serial numbers. The hardware manager supports multiple formats:</p>

<h4 id="method-1-standard-format-with-space-separated-values">Method 1: Standard format with space-separated values</h4>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">metal3.io/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">BareMetalHost</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-ha-server</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">metal3</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">online</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">bootMode</span><span class="pi">:</span> <span class="s">UEFI</span>
  <span class="na">image</span><span class="pi">:</span>
    <span class="na">url</span><span class="pi">:</span> <span class="s2">"</span><span class="s">oci://debian:13"</span>
  <span class="na">rootDeviceHints</span><span class="pi">:</span>
    <span class="c1"># Two space-separated serial numbers enable RAID1</span>
    <span class="na">serialNumber</span><span class="pi">:</span> <span class="s2">"</span><span class="s">DISK1_SERIAL</span><span class="nv"> </span><span class="s">DISK2_SERIAL"</span>
</code></pre></div></div>

<h4 id="method-2-simplified-format-via-annotation">Method 2: Simplified format via annotation</h4>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">metal3.io/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">BareMetalHost</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-ha-server-alt</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">metal3</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="na">bmh.metal3.io/oci_image</span><span class="pi">:</span> <span class="s2">"</span><span class="s">debian:13"</span>
    <span class="c1"># Simplified RAID1 hint format</span>
    <span class="na">bmh.metal3.io/root_device_hints</span><span class="pi">:</span> <span class="s2">"</span><span class="s">serial=DISK1_SERIAL</span><span class="nv"> </span><span class="s">DISK2_SERIAL"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">online</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">bootMode</span><span class="pi">:</span> <span class="s">UEFI</span>
</code></pre></div></div>

<p>With RAID1 enabled, the hardware manager will:</p>

<ul>
  <li>Clean both disks (remove existing partitions, RAID arrays, and LVM)</li>
  <li>Create identical partition layouts on both disks</li>
  <li>Set up a RAID1 array (<code class="language-plaintext highlighter-rouge">/dev/md0</code>) for the LVM physical volume</li>
  <li>Install GRUB to both EFI partitions</li>
  <li>Configure a GRUB update hook to sync EFI partitions via rsync</li>
</ul>

<h3 id="disk-wipe-mode-configuration">Disk Wipe Mode Configuration</h3>

<p>By default, the hardware manager wipes all block devices for RAID1
configurations (to prevent stray RAID/LVM metadata issues) and only target
disks for single-disk setups. You can override this behavior:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">metal3.io/v1alpha1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">BareMetalHost</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-server</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">metal3</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="c1"># Control disk cleaning behavior</span>
    <span class="c1"># "all" - Wipe all block devices (recommended for RAID1)</span>
    <span class="c1"># "target" - Wipe only target disk(s) from root device hints</span>
    <span class="na">bmh.metal3.io/disk_wipe_mode</span><span class="pi">:</span> <span class="s2">"</span><span class="s">all"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">online</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">bootMode</span><span class="pi">:</span> <span class="s">UEFI</span>
  <span class="na">image</span><span class="pi">:</span>
    <span class="na">url</span><span class="pi">:</span> <span class="s2">"</span><span class="s">oci://ubuntu:24.04"</span>
  <span class="na">rootDeviceHints</span><span class="pi">:</span>
    <span class="na">serialNumber</span><span class="pi">:</span> <span class="s2">"</span><span class="s">DISK_SERIAL_NUMBER"</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">disk_wipe_mode</code> annotation is useful when:</p>

<ul>
  <li>You have multiple disks and want to ensure clean RAID/LVM state (<code class="language-plaintext highlighter-rouge">all</code>)</li>
  <li>You want to preserve data on non-target disks (<code class="language-plaintext highlighter-rouge">target</code>)</li>
  <li>You’re migrating from a previous RAID configuration</li>
</ul>

<h3 id="metal3datatemplate-configuration">Metal3DataTemplate Configuration</h3>

<p>When using annotations (instead of <code class="language-plaintext highlighter-rouge">spec.image.url</code>), configure your
Metal3DataTemplate to pass them to the configdrive:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">infrastructure.cluster.x-k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Metal3DataTemplate</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-data-template</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">metal3</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">clusterName</span><span class="pi">:</span> <span class="s">my-cluster</span>
  <span class="na">metaData</span><span class="pi">:</span>
    <span class="na">fromAnnotations</span><span class="pi">:</span>
    <span class="c1"># Optional: Pass OCI image annotation (only if not using spec.image.url)</span>
    <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">oci_image</span>
      <span class="na">object</span><span class="pi">:</span> <span class="s">baremetalhost</span>
      <span class="na">annotation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bmh.metal3.io/oci_image"</span>
    <span class="c1"># Optional: Pass simplified root device hint</span>
    <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">root_device_hints</span>
      <span class="na">object</span><span class="pi">:</span> <span class="s">baremetalhost</span>
      <span class="na">annotation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bmh.metal3.io/root_device_hints"</span>
    <span class="c1"># Optional: Pass disk wipe mode</span>
    <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">disk_wipe_mode</span>
      <span class="na">object</span><span class="pi">:</span> <span class="s">baremetalhost</span>
      <span class="na">annotation</span><span class="pi">:</span> <span class="s2">"</span><span class="s">bmh.metal3.io/disk_wipe_mode"</span>
    <span class="na">objectNames</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">name</span>
      <span class="na">object</span><span class="pi">:</span> <span class="s">machine</span>
    <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">local-hostname</span>
      <span class="na">object</span><span class="pi">:</span> <span class="s">machine</span>
    <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">local_hostname</span>
      <span class="na">object</span><span class="pi">:</span> <span class="s">machine</span>
    <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">metal3-name</span>
      <span class="na">object</span><span class="pi">:</span> <span class="s">baremetalhost</span>
    <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">metal3-namespace</span>
      <span class="na">object</span><span class="pi">:</span> <span class="s">baremetalhost</span>
  <span class="na">networkData</span><span class="pi">:</span>
    <span class="na">links</span><span class="pi">:</span>
      <span class="na">ethernets</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">enp1s0</span>
        <span class="na">macAddress</span><span class="pi">:</span>
          <span class="na">fromHostInterface</span><span class="pi">:</span> <span class="s">enp1s0</span>
        <span class="na">type</span><span class="pi">:</span> <span class="s">phy</span>
    <span class="na">networks</span><span class="pi">:</span>
      <span class="na">ipv4</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">id</span><span class="pi">:</span> <span class="s">baremetalv4</span>
        <span class="na">ipAddressFromIPPool</span><span class="pi">:</span> <span class="s">my-ip-pool</span>
        <span class="na">link</span><span class="pi">:</span> <span class="s">enp1s0</span>
        <span class="na">routes</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">gateway</span><span class="pi">:</span>
            <span class="na">fromIPPool</span><span class="pi">:</span> <span class="s">my-ip-pool</span>
          <span class="na">network</span><span class="pi">:</span> <span class="s">0.0.0.0</span>
          <span class="na">prefix</span><span class="pi">:</span> <span class="m">0</span>
    <span class="na">services</span><span class="pi">:</span>
      <span class="na">dns</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">8.8.8.8</span>
</code></pre></div></div>

<blockquote>
  <p><strong>Note:</strong> When using <code class="language-plaintext highlighter-rouge">spec.image.url</code> with the <code class="language-plaintext highlighter-rouge">oci://</code> prefix, you don’t
need to pass the <code class="language-plaintext highlighter-rouge">oci_image</code> annotation through Metal3DataTemplate. The
hardware manager reads directly from <code class="language-plaintext highlighter-rouge">instance_info.image_source</code>. This is
the recommended approach for newer deployments.</p>
</blockquote>

<h2 id="building-an-ipa-image-with-the-hardware-manager">Building an IPA Image with the Hardware Manager</h2>

<p>To use this hardware manager, you need to build a custom IPA ramdisk
image using
<a href="https://opendev.org/openstack/ironic-python-agent-builder">ironic-python-agent-builder</a>.
This tool uses <a href="https://docs.openstack.org/diskimage-builder/latest/">diskimage-builder</a>
(DIB) to create bootable ramdisk images containing the IPA and any
custom elements you need.</p>

<h3 id="required-packages">Required Packages</h3>

<p>The hardware manager requires several packages to be present in the
IPA ramdisk:</p>

<table>
  <thead>
    <tr>
      <th>Package</th>
      <th>Purpose</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">crane</code></td>
      <td>OCI image extraction from container registries</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">mdadm</code></td>
      <td>Software RAID array management</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">lvm2</code></td>
      <td>Logical Volume Manager for root filesystem</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">parted</code></td>
      <td>Disk partitioning</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">dosfstools</code></td>
      <td>FAT32 filesystem creation for EFI partition</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">grub2-efi-*</code></td>
      <td>UEFI bootloader installation</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">curl</code></td>
      <td>Downloading files during deployment</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">rsync</code></td>
      <td>EFI partition synchronization for RAID</td>
    </tr>
  </tbody>
</table>

<h3 id="custom-dib-elements">Custom DIB Elements</h3>

<p>DIB elements are modular components that customize the image build.
Each element is a directory containing scripts that run at different
phases of the build:</p>

<table>
  <thead>
    <tr>
      <th>Directory</th>
      <th>Phase</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">extra-data.d/</code></td>
      <td>Pre-build</td>
      <td>Copy files into build environment</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">install.d/</code></td>
      <td>Chroot</td>
      <td>Run inside chroot during build</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">post-install.d/</code></td>
      <td>Post-install</td>
      <td>Run after package installation</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">finalise.d/</code></td>
      <td>Finalize</td>
      <td>Run at end of build process</td>
    </tr>
  </tbody>
</table>

<p>Scripts are named with a numeric prefix (e.g., <code class="language-plaintext highlighter-rouge">50-crane</code>) to control
execution order.</p>

<!-- markdownlint-disable MD033 -->

<details>
  <summary>DIB element: crane (OCI image tool)</summary>
  <div>

    <!-- markdownlint-enable MD033 -->

    <p>Create a DIB element to install Google’s <code class="language-plaintext highlighter-rouge">crane</code> tool for OCI image
extraction. Create the following directory structure:</p>

    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="syntax"><code>crane/
├── element-deps
└── install.d/
    └── 50-crane
</code></pre></div>    </div>

    <p>The <code class="language-plaintext highlighter-rouge">element-deps</code> file can be empty or list dependencies. The install
script (<code class="language-plaintext highlighter-rouge">install.d/50-crane</code>):</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c">#!/bin/bash</span>

<span class="c"># https://docs.openstack.org/diskimage-builder/latest/developer/developing_elements.html</span>

<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DIB_DEBUG_TRACE</span><span class="k">:-</span><span class="nv">0</span><span class="k">}</span><span class="s2">"</span> <span class="nt">-gt</span> 0 <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">set</span> <span class="nt">-x</span>
<span class="k">fi

</span><span class="nb">set</span> <span class="nt">-eu</span>
<span class="nb">set</span> <span class="nt">-o</span> pipefail

<span class="nv">CRANE_VERSION</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">DIB_CRANE_VERSION</span><span class="k">:-</span><span class="nv">latest</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># Detect architecture</span>
<span class="nv">ARCH</span><span class="o">=</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span>
<span class="k">case</span> <span class="s2">"</span><span class="k">${</span><span class="nv">ARCH</span><span class="k">}</span><span class="s2">"</span> <span class="k">in
    </span>x86_64<span class="p">)</span>
        <span class="nv">CRANE_ARCH</span><span class="o">=</span><span class="s2">"x86_64"</span>
        <span class="p">;;</span>
    aarch64<span class="p">)</span>
        <span class="nv">CRANE_ARCH</span><span class="o">=</span><span class="s2">"arm64"</span>
        <span class="p">;;</span>
    <span class="k">*</span><span class="p">)</span>
        <span class="nb">echo</span> <span class="s2">"Unsupported architecture: </span><span class="k">${</span><span class="nv">ARCH</span><span class="k">}</span><span class="s2">"</span>
        <span class="nb">exit </span>1
        <span class="p">;;</span>
<span class="k">esac</span>

<span class="nb">echo</span> <span class="s2">"Installing crane (</span><span class="k">${</span><span class="nv">CRANE_VERSION</span><span class="k">}</span><span class="s2">) for </span><span class="k">${</span><span class="nv">CRANE_ARCH</span><span class="k">}</span><span class="s2">..."</span>

<span class="c"># Get the download URL</span>
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CRANE_VERSION</span><span class="k">}</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"latest"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nv">DOWNLOAD_URL</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://api.github.com/repos/google/go-containerregistry/releases/latest |
        <span class="nb">grep</span> <span class="s2">"browser_download_url.*Linux_</span><span class="k">${</span><span class="nv">CRANE_ARCH</span><span class="k">}</span><span class="s2">.tar.gz"</span> |
        <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">'"'</span> <span class="nt">-f</span> 4<span class="si">)</span>
<span class="k">else
    </span><span class="nv">DOWNLOAD_URL</span><span class="o">=</span><span class="s2">"https://github.com/google/go-containerregistry/releases/download/</span><span class="k">${</span><span class="nv">CRANE_VERSION</span><span class="k">}</span><span class="s2">/go-containerregistry_Linux_</span><span class="k">${</span><span class="nv">CRANE_ARCH</span><span class="k">}</span><span class="s2">.tar.gz"</span>
<span class="k">fi

if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DOWNLOAD_URL</span><span class="k">}</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="s2">"Failed to determine crane download URL"</span>
    <span class="nb">exit </span>1
<span class="k">fi

</span><span class="nb">echo</span> <span class="s2">"Downloading crane from: </span><span class="k">${</span><span class="nv">DOWNLOAD_URL</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># Download and extract crane</span>
<span class="nv">TEMP_DIR</span><span class="o">=</span><span class="si">$(</span><span class="nb">mktemp</span> <span class="nt">-d</span><span class="si">)</span>
curl <span class="nt">-sL</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DOWNLOAD_URL</span><span class="k">}</span><span class="s2">"</span> | <span class="nb">tar</span> <span class="nt">-xz</span> <span class="nt">-C</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TEMP_DIR</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># Install crane binary</span>
<span class="nb">install</span> <span class="nt">-m</span> 755 <span class="s2">"</span><span class="k">${</span><span class="nv">TEMP_DIR</span><span class="k">}</span><span class="s2">/crane"</span> /usr/local/bin/crane

<span class="c"># Cleanup</span>
<span class="nb">rm</span> <span class="nt">-rf</span> <span class="s2">"</span><span class="k">${</span><span class="nv">TEMP_DIR</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># Verify installation</span>
<span class="k">if </span>crane version<span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="s2">"crane installed successfully"</span>
<span class="k">else
    </span><span class="nb">echo</span> <span class="s2">"crane installation verification failed"</span>
    <span class="nb">exit </span>1
<span class="k">fi</span>
</code></pre></div>    </div>

  </div>
</details>

<!-- markdownlint-disable MD033 -->

<details>
  <summary>DIB element: packages-install (extra packages)</summary>
  <div>

    <!-- markdownlint-enable MD033 -->

    <p>Create a DIB element that installs packages from the <code class="language-plaintext highlighter-rouge">DIB_EXTRA_PACKAGES</code>
environment variable:</p>

    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="syntax"><code>packages-install/
├── element-deps
└── install.d/
    └── 50-packages-install
</code></pre></div>    </div>

    <p>The install script (<code class="language-plaintext highlighter-rouge">install.d/50-packages-install</code>):</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="c">#!/bin/bash</span>

<span class="c"># https://docs.openstack.org/diskimage-builder/latest/developer/developing_elements.html</span>

<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DIB_DEBUG_TRACE</span><span class="k">:-</span><span class="nv">0</span><span class="k">}</span><span class="s2">"</span> <span class="nt">-gt</span> 0 <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">set</span> <span class="nt">-x</span>
<span class="k">fi

</span><span class="nb">set</span> <span class="nt">-eu</span>
<span class="nb">set</span> <span class="nt">-o</span> pipefail

<span class="c"># Enable CRB (CodeReady Builder) repository and install EPEL</span>
<span class="nb">echo</span> <span class="s2">"Enabling CRB repository..."</span>
dnf config-manager <span class="nt">--set-enabled</span> crb <span class="o">||</span> <span class="nb">true</span>

<span class="c"># Detect CentOS version and install appropriate EPEL</span>
<span class="k">if</span> <span class="o">[</span> <span class="nt">-f</span> /etc/os-release <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
    <span class="c"># shellcheck disable=SC1091</span>
    <span class="nb">.</span> /etc/os-release
    <span class="k">case</span> <span class="s2">"</span><span class="k">${</span><span class="nv">VERSION_ID</span><span class="p">%%.*</span><span class="k">}</span><span class="s2">"</span> <span class="k">in
        </span>9<span class="p">)</span>
            <span class="nb">echo</span> <span class="s2">"Installing EPEL for CentOS 9..."</span>
            dnf <span class="nb">install</span> <span class="nt">-y</span> https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm <span class="o">||</span> <span class="nb">true</span>
            <span class="p">;;</span>
        10<span class="p">)</span>
            <span class="nb">echo</span> <span class="s2">"Installing EPEL for CentOS 10..."</span>
            dnf <span class="nb">install</span> <span class="nt">-y</span> https://dl.fedoraproject.org/pub/epel/epel-release-latest-10.noarch.rpm <span class="o">||</span> <span class="nb">true</span>
            <span class="p">;;</span>
        <span class="k">*</span><span class="p">)</span>
            <span class="nb">echo</span> <span class="s2">"Unknown CentOS version: </span><span class="k">${</span><span class="nv">VERSION_ID</span><span class="k">}</span><span class="s2">, skipping EPEL installation"</span>
            <span class="p">;;</span>
    <span class="k">esac</span>
<span class="k">fi

if</span> <span class="o">[</span> <span class="nt">-z</span> <span class="s2">"</span><span class="k">${</span><span class="nv">DIB_EXTRA_PACKAGES</span><span class="k">:-}</span><span class="s2">"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then
    </span><span class="nb">echo</span> <span class="s2">"No extra packages specified via DIB_EXTRA_PACKAGES, skipping"</span>
    <span class="nb">exit </span>0
<span class="k">fi

</span><span class="nb">echo</span> <span class="s2">"Updating system packages..."</span>
dnf update <span class="nt">-y</span>

<span class="nb">echo</span> <span class="s2">"Installing extra packages: </span><span class="k">${</span><span class="nv">DIB_EXTRA_PACKAGES</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># shellcheck disable=SC2086</span>
dnf <span class="nb">install</span> <span class="nt">-y</span> <span class="k">${</span><span class="nv">DIB_EXTRA_PACKAGES</span><span class="k">}</span>

<span class="nb">echo</span> <span class="s2">"Cleaning package cache..."</span>
dnf clean all

<span class="nb">echo</span> <span class="s2">"Extra packages installation complete"</span>
</code></pre></div>    </div>

  </div>
</details>

<h3 id="building-the-image">Building the Image</h3>

<p>Set the <code class="language-plaintext highlighter-rouge">ELEMENTS_PATH</code> to include your custom elements directory, then
run the builder:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nb">export </span><span class="nv">ELEMENTS_PATH</span><span class="o">=</span><span class="s2">"/path/to/your/dib-elements"</span>

<span class="nb">export </span><span class="nv">DIB_EXTRA_PACKAGES</span><span class="o">=</span><span class="s2">"jq yq mdadm lvm2 curl parted util-linux </span><span class="se">\</span><span class="s2">
    squashfs-tools xfsprogs dosfstools grub2-efi-x64 grub2-tools rsync"</span>

ironic-python-agent-builder <span class="se">\</span>
    <span class="nt">-o</span> ipa-custom <span class="se">\</span>
    <span class="nt">-e</span> extra-hardware <span class="se">\</span>
    <span class="nt">-e</span> crane <span class="se">\</span>
    <span class="nt">-e</span> packages-install <span class="se">\</span>
    <span class="nt">--release</span> 9-stream centos
</code></pre></div></div>

<p>This produces two files:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ipa-custom.kernel</code> - The Linux kernel</li>
  <li><code class="language-plaintext highlighter-rouge">ipa-custom.initramfs</code> - The ramdisk containing IPA and tools</li>
</ul>

<p>For ARM64 builds, the grub packages differ:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nb">export </span><span class="nv">DIB_EXTRA_PACKAGES</span><span class="o">=</span><span class="s2">"jq yq mdadm lvm2 curl parted util-linux </span><span class="se">\</span><span class="s2">
    squashfs-tools xfsprogs dosfstools grub2-efi-aa64 grub2-tools rsync"</span>
</code></pre></div></div>

<h2 id="installing-the-hardware-manager">Installing the Hardware Manager</h2>

<p>The hardware manager must be placed in the IPA hardware managers directory
and registered in <code class="language-plaintext highlighter-rouge">setup.cfg</code>.</p>

<p><strong>File location:</strong></p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="syntax"><code>ironic_python_agent/hardware_managers/deb_oci_efi_lvm.py
</code></pre></div></div>

<p><strong>setup.cfg entry point:</strong></p>

<p>Add the following entry to the <code class="language-plaintext highlighter-rouge">ironic_python_agent.hardware_managers</code>
section in <code class="language-plaintext highlighter-rouge">setup.cfg</code>:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="syntax"><code><span class="nn">[entry_points]</span>
<span class="py">ironic_python_agent.hardware_managers</span> <span class="p">=</span>
    <span class="py">deb_oci_efi_lvm</span> <span class="p">=</span> <span class="s">ironic_python_agent.hardware_managers.deb_oci_efi_lvm:DebOCIEFILVMHardwareManager</span>
</code></pre></div></div>

<p>This registers the hardware manager as a plugin, allowing IPA to
discover and load it at runtime.</p>

<h3 id="source-code">Source Code</h3>

<p>The implementation is shown below in expandable sections. Full source:
<a href="https://github.com/s3rj1k/ironic-python-agent/blob/custom_deploy/ironic_python_agent/hardware_managers/deb_oci_efi_lvm.py">deb_oci_efi_lvm.py</a>.</p>

<blockquote>
  <p><strong>Note:</strong> The code below uses a custom <code class="language-plaintext highlighter-rouge">run_command</code> helper function
instead of IPA’s built-in
<a href="https://opendev.org/openstack/ironic-python-agent/src/branch/master/ironic_python_agent/utils.py"><code class="language-plaintext highlighter-rouge">ironic_python_agent.utils.execute</code></a>.
This was a deliberate choice to minimize dependencies on IPA internals,
avoiding the need to keep the hardware manager in constant sync with
IPA changes. However, reusing IPA’s existing utilities is a valid
alternative approach.</p>
</blockquote>

<!-- markdownlint-disable MD033 -->

<details>
<summary>Imports and constants</summary>

Standard library and IPA imports, plus configuration constants for
device paths, filesystem labels, and retry parameters.

```python
# SPDX-License-Identifier: Apache-2.0
# SPDX-FileCopyrightText: 2025 s3rj1k

"""Debian/Ubuntu OCI EFI LVM deployment hardware manager.

This hardware manager deploys Debian-based OCI container images with:
- EFI boot partition
- LVM on root partition
- Optional RAID1 support for two-disk configurations
"""

import os
import platform
import re
import shutil
import stat as stat_module
import subprocess
import tempfile
import time

import yaml

from oslo_log import log

from ironic_python_agent import device_hints
from ironic_python_agent import hardware

LOG = log.getLogger(__name__)

# Default OCI image (can be overridden via node metadata 'oci_image')
DEFAULT_OCI_IMAGE = "ubuntu:24.04"

# Device/filesystem constants
RAID_DEVICE = "/dev/md0"
VG_NAME = "vg_root"
LV_NAME = "lv_root"
ROOT_FS_LABEL = "ROOTFS"
BOOT_FS_LABEL = "EFI"
BOOT_FS_LABEL2 = "EFI2"
DEVICE_PROBE_MAX_ATTEMPTS = 5
DEVICE_PROBE_DELAY = 5
DEVICE_WAIT_MAX_ATTEMPTS = 5
DEVICE_WAIT_DELAY = 5
```

</details>

<details>
<summary>run_command</summary>

Wrapper around `subprocess.run` with logging support.

```python
def run_command(cmd, check=True, capture_output=True, timeout=300):
    """Run a shell command with logging.

    :param cmd: Command as list of strings
    :param check: Whether to raise on non-zero exit
    :param capture_output: Whether to capture stdout/stderr
    :param timeout: Command timeout in seconds
    :returns: CompletedProcess object
    :raises: subprocess.CalledProcessError on failure if check=True
    """
    LOG.debug("Running command: %s", " ".join(cmd))
    result = subprocess.run(
        cmd, check=check, capture_output=capture_output, text=True, timeout=timeout
    )
    if result.stdout:
        LOG.debug("stdout: %s", result.stdout)
    if result.stderr:
        LOG.debug("stderr: %s", result.stderr)
    return result
```

</details>

<details>
<summary>is_efi_system</summary>

Checks if the system booted in UEFI mode by testing for `/sys/firmware/efi`.

```python
def is_efi_system():
    """Check if the system is booted in EFI mode.

    :returns: True if running under EFI, False otherwise
    """
    return os.path.isdir("/sys/firmware/efi")
```

</details>

<details>
<summary>probe_device</summary>

Runs `partprobe` and waits for device to appear in the kernel.

```python
def probe_device(device):
    """Probe device until it is visible in the kernel.

    :param device: Device path (e.g., /dev/sda)
    :raises: RuntimeError if device doesn't appear after max attempts
    """
    for attempt in range(DEVICE_PROBE_MAX_ATTEMPTS):
        run_command(["partprobe", device], check=False)
        time.sleep(DEVICE_PROBE_DELAY)
        if os.path.exists(device):
            LOG.debug("Device %s visible after %d attempt(s)", device, attempt + 1)
            return
    raise RuntimeError(
        f"Device {device} not visible after " f"{DEVICE_PROBE_MAX_ATTEMPTS} attempts"
    )
```

</details>

<details>
<summary>has_interactive_users</summary>

Checks for logged-in users via `who` command, used to pause deployment
for debugging via BMC console.

```python
def has_interactive_users():
    """Check if there are any interactive users logged in.

    Uses 'who' command to check for logged-in users, which indicates
    someone has connected via BMC console for debugging.

    :returns: Boolean indicating if interactive users are logged in
    """
    try:
        result = run_command(["who"], check=True, timeout=5)
        # who returns empty output if no users are logged in
        users = result.stdout.strip()
        if users:
            LOG.debug("Interactive users detected: %s", users)
            return True
        return False
    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, OSError) as e:
        LOG.warning("Failed to check for interactive users: %s", e)
        return False
```

</details>

<details>
<summary>get_configdrive_data</summary>

Extracts configdrive dictionary from node's `instance_info`.

```python
def get_configdrive_data(node):
    """Extract configdrive data from node instance_info.

    :param node: Node dictionary containing instance_info
    :returns: Dictionary containing configdrive data
    :raises: ValueError if node is invalid or configdrive data is missing
    """
    if node is None:
        raise ValueError("Node cannot be None")
    if not isinstance(node, dict):
        raise ValueError("Node must be a dictionary")

    instance_info = node.get("instance_info", {})
    if not isinstance(instance_info, dict):
        raise ValueError("instance_info must be a dictionary")

    configdrive = instance_info.get("configdrive")
    if configdrive is None:
        raise ValueError("configdrive not found in instance_info")

    if not isinstance(configdrive, dict):
        raise ValueError("configdrive must be a dictionary")

    LOG.info("Extracted configdrive data: %s", configdrive)
    return configdrive
```

</details>

<details>
<summary>parse_prefixed_hint_string</summary>

Parses simplified hint format like `serial=ABC123` or `wwn=0x123456` into
IPA hint dictionary format. Supports RAID1 with space-separated values.

```python
def parse_prefixed_hint_string(hint_string):
    """Parse a prefixed hint string into a hints dictionary.

    Supports simplified format for cloud-init/annotation use cases:
    - 'serial=ABC123' -&gt; {'serial': 's== ABC123'}
    - 'wwn=0x123456' -&gt; {'wwn': 's== 0x123456'}
    - 'serial=ABC123 DEF456' -&gt; {'serial': 's== ABC123 DEF456'} (RAID1)
    - 'wwn=0x123 0x456' -&gt; {'wwn': 's== 0x123 0x456'} (RAID1)

    :param hint_string: String with format 'hint_type=value1 [value2]'
    :returns: Dictionary containing root_device hints
    :raises: ValueError if format is invalid
    """
    if not hint_string or not isinstance(hint_string, str):
        raise ValueError("Hint string must be a non-empty string")

    hint_string = hint_string.strip()
    if "=" not in hint_string:
        raise ValueError(
            'Hint string must contain "=" separator. '
            'Expected format: "serial=VALUE" or "wwn=VALUE"'
        )

    # Split on first equals only
    parts = hint_string.split("=", 1)
    if len(parts) != 2:
        raise ValueError("Invalid hint string format")

    hint_type = parts[0].strip().lower()
    hint_values = parts[1].strip()

    if hint_type not in ("serial", "wwn"):
        raise ValueError(
            f'Unsupported hint type "{hint_type}". '
            'Only "serial" and "wwn" are supported.'
        )

    if not hint_values:
        raise ValueError(f"No value provided for {hint_type} hint")

    # Add s== operator prefix (string equality)
    hint_with_operator = f"s== {hint_values}"

    LOG.info(
        'Parsed prefixed hint string "%s" -&gt; {"%s": "%s"}',
        hint_string,
        hint_type,
        hint_with_operator,
    )

    return {hint_type: hint_with_operator}
```

</details>

<details>
<summary>get_root_device_hints</summary>

Extracts root device hints from configdrive annotation or node's
`instance_info`. Supports both simplified string format
(`serial=ABC123`) and standard dictionary format.

```python
def get_root_device_hints(node, configdrive_data):
    """Extract root_device hints from node instance_info or annotation.

    Priority order:
    1. configdrive meta_data.root_device_hints (prefixed string format)
    1. node.instance_info.root_device (dict format with operators)

    :param node: Node dictionary containing instance_info
    :param configdrive_data: Configdrive dictionary
    :returns: Dictionary containing root_device hints
    :raises: ValueError if node is invalid or root_device not found anywhere
    """
    if node is None:
        raise ValueError("Node cannot be None")
    if not isinstance(node, dict):
        raise ValueError("Node must be a dictionary")

    instance_info = node.get("instance_info", {})
    if not isinstance(instance_info, dict):
        raise ValueError("instance_info must be a dictionary")

    # Check annotation first (via configdrive metadata)
    meta_data = configdrive_data.get("meta_data", {})
    annotation_hints = meta_data.get("root_device_hints")

    if annotation_hints is not None:
        # Annotations use prefixed string format only
        if not isinstance(annotation_hints, str):
            raise ValueError(
                "root_device_hints from annotation must be a string "
                'in format "serial=VALUE" or "wwn=VALUE"'
            )

        parsed_hints = parse_prefixed_hint_string(annotation_hints)
        LOG.info("Using root_device hints from annotation: %s", parsed_hints)
        return parsed_hints

    # Fall back to instance_info
    root_device = instance_info.get("root_device")
    if root_device is not None:
        if not isinstance(root_device, dict):
            raise ValueError("root_device must be a dictionary")
        LOG.info("Using root_device hints from instance_info: %s", root_device)
        return root_device

    # Neither source provided root_device hints
    raise ValueError("root_device hints not found in instance_info or annotation")
```

</details>

<details>
<summary>find_device_by_hints</summary>

Uses IPA's `device_hints` module to find a block device by serial or WWN.

```python
def find_device_by_hints(hints):
    """Find a single block device matching the given hints.

    :param hints: Dictionary containing device hints (serial or wwn)
    :returns: Device path (e.g., /dev/sda)
    :raises: ValueError if no device or multiple devices match
    """
    devices = hardware.list_all_block_devices()
    LOG.debug("list_all_block_devices returned type: %s", type(devices).__name__)
    LOG.info("Found %d block devices", len(devices))
    serialized_devs = [dev.serialize() for dev in devices]

    matched_raw = device_hints.find_devices_by_hints(serialized_devs, hints)
    matched = list(matched_raw)

    if not matched:
        raise ValueError(f"No device found matching hints: {hints}")

    if len(matched) &gt; 1:
        device_names = [dev["name"] for dev in matched]
        raise ValueError(
            f"Multiple devices match hints: {device_names}. "
            f"Hints must match exactly one device."
        )

    return matched[0]["name"]
```

</details>

<details>
<summary>parse_hint_values</summary>

Parses hint strings, stripping operator prefixes and splitting multiple
values for RAID1 configurations.

```python
def parse_hint_values(hint):
    """Parse hint value, handling operator prefixes like 's=='.

    Returns list of values without the operator prefix.
    For RAID1: 's== SERIAL1 SERIAL2' -&gt; ['SERIAL1', 'SERIAL2']
    For single: 's== SERIAL1' -&gt; ['SERIAL1']
    For plain: 'SERIAL1 SERIAL2' -&gt; ['SERIAL1', 'SERIAL2']

    :param hint: Hint string value (may include operator prefix)
    :returns: List of values without operator prefix
    """
    if not hint:
        return []

    parts = hint.split()

    # Check if first part is an operator (e.g., 's==', 'int', etc.)
    operators = ("s==", "s!=", "<in>", "<or>", "int", "float")
    if parts and parts[0] in operators:
        return parts[1:]  # Skip the operator

    return parts
```

&lt;/details&gt;

<details>
<summary>resolve_root_devices</summary>

Resolves device paths from hints. Returns one device for single-disk
or two devices for RAID1 configuration.

```python
def resolve_root_devices(root_device_hints):
    """Resolve root device path(s) from hints.

    Only serial or wwn hints are supported. If the hint contains two
    space-separated values, both devices are resolved for RAID1 setup.

    :param root_device_hints: Dictionary containing root device hints
    :returns: Tuple of device paths - (primary,) for single device or
              (primary, secondary) for RAID1 configuration
    :raises: ValueError if device cannot be resolved or hints are invalid
    """
    if root_device_hints is None:
        raise ValueError("root_device_hints cannot be None")

    if not isinstance(root_device_hints, dict):
        raise ValueError("root_device_hints must be a dictionary")

    # Validate that only serial or wwn hints are present
    serial_hint = root_device_hints.get("serial")
    wwn_hint = root_device_hints.get("wwn")

    if not serial_hint and not wwn_hint:
        raise ValueError("root_device_hints must contain serial or wwn hint")

    # Check for unsupported hint types
    supported_hints = {"serial", "wwn"}
    provided_hints = set(root_device_hints.keys())
    unsupported = provided_hints - supported_hints

    if unsupported:
        raise ValueError(
            f"Unsupported root_device hints: {unsupported}. "
            f"Only serial and wwn are supported."
        )

    LOG.info("Resolving root devices from hints: %s", root_device_hints)

    # Parse hints - may contain one or two values (with optional operator)
    serial_values = parse_hint_values(serial_hint)
    wwn_values = parse_hint_values(wwn_hint)

    # Determine if this is a RAID1 configuration
    is_raid = len(serial_values) == 2 or len(wwn_values) == 2

    if is_raid:
        LOG.info("RAID1 configuration detected")

    # Resolve primary device
    primary_hints = {}
    if serial_values:
        primary_hints["serial"] = serial_values[0]
    if wwn_values:
        primary_hints["wwn"] = wwn_values[0]

    primary_device = find_device_by_hints(primary_hints)
    LOG.info("Resolved primary device: %s", primary_device)

    if not is_raid:
        return (primary_device,)

    # Resolve secondary device for RAID1
    secondary_hints = {}
    if len(serial_values) == 2:
        secondary_hints["serial"] = serial_values[1]
    if len(wwn_values) == 2:
        secondary_hints["wwn"] = wwn_values[1]

    secondary_device = find_device_by_hints(secondary_hints)
    LOG.info("Resolved secondary device: %s", secondary_device)

    return (primary_device, secondary_device)
```

</details>

<details>
<summary>get_oci_image</summary>

Gets OCI image reference with priority: `spec.image.url` (with `oci://`
prefix) &gt; configdrive annotation &gt; default `ubuntu:24.04`.

```python
def get_oci_image(node, configdrive_data):
    """Get OCI image from instance_info, metadata, or use default.

    Priority order:
    1. node.instance_info.image_source with oci:// prefix
    1. configdrive meta_data.oci_image (from annotation)
    1. DEFAULT_OCI_IMAGE

    :param node: Node dictionary containing instance_info
    :param configdrive_data: Configdrive dictionary
    :returns: OCI image reference string (without oci:// prefix)
    """
    oci_image = None

    # Check instance_info first
    instance_info = node.get("instance_info", {})
    image_source = instance_info.get("image_source", "").strip()

    if image_source.startswith("oci://"):
        oci_image = image_source.removeprefix("oci://").strip()
        if not oci_image:
            LOG.warning(
                "Empty OCI image after stripping oci:// prefix, "
                "falling back to annotation/default"
            )
            oci_image = None
        else:
            LOG.info("Using OCI image from instance_info: %s", oci_image)
    else:
        # Fall back to annotation (via configdrive metadata)
        meta_data = configdrive_data.get("meta_data", {})
        annotation_image = (meta_data.get("oci_image") or "").strip()

        if annotation_image:
            oci_image = annotation_image
            LOG.info("Using OCI image from annotation: %s", oci_image)
        else:
            # Fall back to default
            oci_image = DEFAULT_OCI_IMAGE
            LOG.info("Using default OCI image: %s", oci_image)

    return oci_image
```

</details>

<details>
<summary>get_disk_wipe_mode</summary>

Determines disk cleaning behavior based on annotation or setup type. Returns
`all` to wipe all block devices (default for RAID1) or `target` to wipe only
specified disks (default for single disk).

```python
def get_disk_wipe_mode(configdrive_data, is_raid):
    """Get disk wipe mode from configdrive or use default based on setup.

    Priority order:
    1. configdrive meta_data.disk_wipe_mode (from annotation)
    1. Default: "all" for RAID1, "target" for single disk

    :param configdrive_data: Configdrive dictionary
    :param is_raid: Boolean indicating if this is a RAID setup
    :returns: String "all" or "target"
    :raises: ValueError if disk_wipe_mode has invalid value
    """
    meta_data = configdrive_data.get("meta_data", {})
    wipe_mode = (meta_data.get("disk_wipe_mode") or "").strip().lower()

    if wipe_mode:
        if wipe_mode not in ("all", "target"):
            raise ValueError(
                f'Invalid disk_wipe_mode "{wipe_mode}". '
                'Valid values are: "all", "target"'
            )
        LOG.info("Using disk wipe mode from annotation: %s", wipe_mode)
        return wipe_mode

    # Use default based on setup type
    default_mode = "all" if is_raid else "target"
    LOG.info(
        "Using default disk wipe mode for %s setup: %s",
        "RAID1" if is_raid else "single disk",
        default_mode,
    )
    return default_mode
```

</details>

<details>
<summary>get_architecture_config</summary>

Returns architecture-specific settings for x86_64 or ARM64, including
GRUB packages and UEFI target.

```python
def get_architecture_config(oci_image):
    """Get architecture-specific configuration.

    :param oci_image: OCI image reference to use
    :returns: Dictionary with oci_image, oci_platform, uefi_target,
              and grub_packages
    :raises: RuntimeError if architecture is not supported
    """
    machine = platform.machine()

    if machine == "x86_64":
        return {
            "oci_image": oci_image,
            "oci_platform": "linux/amd64",
            "uefi_target": "x86_64-efi",
            "grub_packages": ["grub-efi-amd64", "grub-efi-amd64-signed", "shim-signed"],
        }
    elif machine == "aarch64":
        return {
            "oci_image": oci_image,
            "oci_platform": "linux/arm64",
            "uefi_target": "arm64-efi",
            "grub_packages": ["grub-efi-arm64", "grub-efi-arm64-bin"],
        }
    else:
        raise RuntimeError(f"Unsupported architecture: {machine}")
```

</details>

<details>
<summary>wait_for_device</summary>

Waits for a block device to become available with retries.

```python
def wait_for_device(device):
    """Wait for a block device to become available.

    :param device: Device path (e.g., /dev/sda)
    :returns: True if device is available
    :raises: RuntimeError if device doesn't appear
    """
    for attempt in range(DEVICE_WAIT_MAX_ATTEMPTS):
        if os.path.exists(device):
            try:
                mode = os.stat(device).st_mode
                if stat_module.S_ISBLK(mode):
                    LOG.info("Device %s is available", device)
                    return True
            except OSError:
                pass
        LOG.debug(
            "Waiting for device %s (attempt %d/%d)",
            device,
            attempt + 1,
            DEVICE_WAIT_MAX_ATTEMPTS,
        )
        time.sleep(DEVICE_WAIT_DELAY)

    raise RuntimeError(f"Device {device} did not become available")
```

</details>

<details>
<summary>get_partition_path</summary>

Returns partition path, handling NVMe and MMC naming conventions.

```python
def get_partition_path(device, partition_number):
    """Get the partition path for a device.

    :param device: Base device path (e.g., /dev/sda)
    :param partition_number: Partition number
    :returns: Partition path (e.g., /dev/sda1 or /dev/nvme0n1p1)
    """
    if re.match(r".*/nvme\d+n\d+$", device) or re.match(r".*/mmcblk\d+$", device):
        return f"{device}p{partition_number}"

    return f"{device}{partition_number}"
```

</details>

<details>
<summary>clean_device</summary>

Removes existing partitions, RAID arrays, LVM structures, and wipes
the device.

```python
def clean_device(device):
    """Clean a device of existing partitions, RAID, and LVM.

    :param device: Device path to clean
    """
    LOG.info("Cleaning device: %s", device)

    # Stop any RAID arrays using this device
    try:
        result = run_command(["lsblk", "-nlo", "NAME,TYPE", device], check=False)
        for line in result.stdout.strip().split("\n"):
            parts = line.split()
            if len(parts) &gt;= 2 and parts[1] in (
                "raid1",
                "raid0",
                "raid5",
                "raid6",
                "raid10",
            ):
                raid_dev = f"/dev/{parts[0]}"
                run_command(["mdadm", "--stop", raid_dev], check=False)
    except Exception:
        pass

    # Remove LVM if present (check device and all its partitions)
    try:
        # Get all block devices (device + partitions)
        result = run_command(["lsblk", "-nlo", "NAME", device], check=False)
        all_devs = []
        for line in result.stdout.strip().split("\n"):
            name = line.strip()
            if name:
                all_devs.append(f"/dev/{name}")

        # Find all VGs that use any of these devices
        vgs_to_remove = set()
        for dev in all_devs:
            result = run_command(["pvs", dev], check=False)
            if result.returncode == 0:
                vg_result = run_command(
                    ["pvs", "--noheadings", "-o", "vg_name", dev], check=False
                )
                vg_name = vg_result.stdout.strip()
                if vg_name:
                    vgs_to_remove.add(vg_name)

        # Deactivate, remove all LVs and VGs
        for vg_name in vgs_to_remove:
            # Deactivate all LVs in this VG
            run_command(["lvchange", "-an", vg_name], check=False)

            lv_result = run_command(
                ["lvs", "--noheadings", "-o", "lv_path", vg_name], check=False
            )
            for lv_path in lv_result.stdout.strip().split("\n"):
                lv_path = lv_path.strip()
                if lv_path:
                    # Try dmsetup remove for stubborn LVs
                    dm_name = lv_path.replace("/dev/", "").replace("/", "-")
                    run_command(
                        ["dmsetup", "remove", "--retry", "-f", dm_name], check=False
                    )
                    run_command(["lvremove", "-ff", lv_path], check=False)
            run_command(["vgremove", "-ff", vg_name], check=False)

        # Remove PVs from all devices
        for dev in all_devs:
            run_command(["pvremove", "-ff", "-y", dev], check=False)
    except Exception:
        pass

    # Zero RAID superblocks
    run_command(["mdadm", "--zero-superblock", "--force", device], check=False)

    # Zero superblocks on partitions
    try:
        result = run_command(["lsblk", "-nlo", "NAME", device], check=False)
        base_name = os.path.basename(device)
        for line in result.stdout.strip().split("\n"):
            name = line.strip()
            if name and name != base_name:
                part_dev = f"/dev/{name}"
                run_command(
                    ["mdadm", "--zero-superblock", "--force", part_dev], check=False
                )
                run_command(["wipefs", "--all", "--force", part_dev], check=False)
    except Exception:
        pass

    # Wipe device
    run_command(["wipefs", "--all", "--force", device], check=False)
    run_command(["sgdisk", "--zap-all", device], check=False)

    # Sync filesystem buffers and wait for udev to settle
    run_command(["sync"], check=False)
    run_command(["udevadm", "settle"], check=False)

    # Probe until device is visible again
    probe_device(device)

    LOG.info("Device %s cleaned", device)
```

</details>

<details>
<summary>clean_all_devices</summary>

Cleans all block devices on the system to remove stray RAID/LVM metadata.
Useful when `disk_wipe_mode` is set to `all` (default for RAID1 setups).

```python
def clean_all_devices():
    """Clean all block devices to remove stray RAID/LVM metadata.

    Useful for nodes that may have multiple disks with old metadata
    from previous deployments.
    """
    LOG.info("Cleaning all block devices on the system")

    try:
        devices = hardware.list_all_block_devices()
        LOG.info("Found %d block devices to clean", len(devices))

        for device_obj in devices:
            device = device_obj.name
            try:
                clean_device(device)
            except Exception as e:
                LOG.warning("Error cleaning device %s: %s", device, e)

        LOG.info("Finished cleaning all block devices")
    except Exception as e:
        LOG.error("Error listing block devices: %s", e)
```

</details>

<details>
<summary>clean_partition_signatures</summary>

Cleans RAID, LVM, and filesystem signatures from a partition without
removing the partition itself. Used internally by `partition_disk()` to
clean partitions before creating RAID arrays, ensuring no stray metadata
causes issues.

```python
def clean_partition_signatures(partition):
    """Clean RAID, LVM, and filesystem signatures from a partition.

    Does not remove the partition itself, only metadata/signatures.

    :param partition: Partition path to clean
    """
    LOG.debug("Cleaning signatures from partition: %s", partition)
    run_command(["pvremove", "-ff", "-y", partition], check=False)
    run_command(["wipefs", "--all", "--force", partition], check=False)
    run_command(["mdadm", "--zero-superblock", "--force", partition], check=False)
```

</details>

<details>
<summary>partition_disk</summary>

Creates GPT partition table with EFI and LVM partitions. Sets up RAID1
array if second device is provided. Calls `clean_partition_signatures()`
before RAID creation to ensure clean metadata.

```python
def partition_disk(
    device, vg_name, lv_name, second_device=None, raid_device=RAID_DEVICE, homehost=None
):
    """Partition disk with EFI and LVM (optionally on RAID).

    :param device: Primary device path
    :param vg_name: Volume group name
    :param lv_name: Logical volume name
    :param second_device: Optional second device for RAID
    :param raid_device: RAID device path
    :param homehost: Hostname for RAID array
    :returns: Tuple of (is_raid, pv_device)
    """
    LOG.info("Partitioning disk: %s", device)

    wait_for_device(device)

    # Ensure udev has finished processing before partitioning
    run_command(["udevadm", "settle"], check=False)

    # Create GPT partition table
    run_command(["parted", "-s", device, "mklabel", "gpt"])

    # Create EFI partition (2GB)
    run_command(
        [
            "parted",
            "-s",
            "-a",
            "optimal",
            device,
            "mkpart",
            "primary",
            "fat32",
            "2MiB",
            "2050MiB",
        ]
    )
    run_command(["parted", "-s", device, "set", "1", "esp", "on"])

    # Create data partition (rest of disk)
    run_command(
        ["parted", "-s", "-a", "optimal", device, "mkpart", "primary", "2050MiB", "99%"]
    )

    is_raid = second_device is not None

    if is_raid:
        run_command(["parted", "-s", device, "set", "2", "raid", "on"])
    else:
        run_command(["parted", "-s", device, "set", "2", "lvm", "on"])

    # Wipe new partitions
    try:
        result = run_command(["lsblk", "-nlo", "NAME", device], check=False)
        base_name = os.path.basename(device)
        for line in result.stdout.strip().split("\n"):
            name = line.strip()
            if name and name != base_name:
                run_command(["wipefs", "-a", f"/dev/{name}"], check=False)
    except Exception:
        pass

    data_partition = get_partition_path(device, 2)
    pv_device = data_partition

    if is_raid:
        probe_device(device)
        probe_device(second_device)

        # Clone partition table to second device
        sfdisk_result = run_command(["sfdisk", "-d", device])
        LOG.debug("Cloning partition table to %s", second_device)
        sfdisk_proc = subprocess.run(
            ["sfdisk", "--force", second_device],
            input=sfdisk_result.stdout,
            capture_output=True,
            text=True,
            check=False,
        )
        if sfdisk_proc.stdout:
            LOG.debug("sfdisk stdout: %s", sfdisk_proc.stdout)
        if sfdisk_proc.stderr:
            LOG.debug("sfdisk stderr: %s", sfdisk_proc.stderr)
        if sfdisk_proc.returncode != 0:
            raise subprocess.CalledProcessError(
                sfdisk_proc.returncode,
                ["sfdisk", "--force", second_device],
                sfdisk_proc.stdout,
                sfdisk_proc.stderr,
            )

        # Randomize partition GUIDs on second device
        run_command(["sgdisk", "--partition-guid=1:R", second_device])
        run_command(["sgdisk", "--partition-guid=2:R", second_device])

        second_data_partition = get_partition_path(second_device, 2)
        probe_device(second_data_partition)

        if not homehost:
            raise RuntimeError("homehost required for RAID configuration")

        # Clean new partitions before creating RAID
        LOG.info("Cleaning partition signatures before RAID creation")
        clean_partition_signatures(data_partition)
        clean_partition_signatures(second_data_partition)

        # Create RAID array
        run_command(
            [
                "mdadm",
                "--create",
                raid_device,
                "--level=1",
                "--raid-devices=2",
                "--metadata=1.2",
                "--name=root",
                "--bitmap=internal",
                f"--homehost={homehost}",
                "--force",
                "--run",
                "--assume-clean",
                data_partition,
                second_data_partition,
            ]
        )

        # Sync filesystem buffers before continuing
        run_command(["sync"], check=False)
        time.sleep(5)
        pv_device = raid_device
    else:
        probe_device(device)

    # Create LVM
    run_command(["pvcreate", "-ff", "-y", "--zero", "y", pv_device])
    run_command(["vgcreate", "-y", vg_name, pv_device])
    run_command(["lvcreate", "-y", "-W", "y", "-n", lv_name, "-l", "100%FREE", vg_name])

    LOG.info("Disk partitioned successfully, is_raid=%s", is_raid)
    return is_raid, pv_device
```

</details>

<details>
<summary>create_filesystems</summary>

Creates FAT32 filesystem on EFI partition and ext4 on root LV.

```python
def create_filesystems(
    efi_partition,
    root_lv_path,
    boot_label=BOOT_FS_LABEL,
    root_label=ROOT_FS_LABEL,
    second_efi_partition=None,
    boot_label2=BOOT_FS_LABEL2,
):
    """Create filesystems on partitions.

    :param efi_partition: EFI partition path
    :param root_lv_path: Root LV path
    :param boot_label: EFI partition label
    :param root_label: Root partition label
    :param second_efi_partition: Second EFI partition for RAID
    :param boot_label2: Second EFI partition label
    """
    LOG.info("Creating filesystems")

    run_command(["mkfs.vfat", "-F", "32", "-n", boot_label, efi_partition])

    if second_efi_partition:
        run_command(
            ["mkfs.vfat", "-F", "32", "-n", boot_label2, second_efi_partition],
            check=False,
        )

    run_command(["mkfs.ext4", "-F", "-L", root_label, root_lv_path])

    LOG.info("Filesystems created")
```

</details>

<details>
<summary>setup_chroot</summary>

Mounts `/proc`, `/sys`, `/dev` and sets up DNS resolution in chroot.

```python
def setup_chroot(chroot_dir):
    """Set up chroot environment with necessary mounts.

    :param chroot_dir: Path to chroot directory
    """
    LOG.info("Setting up chroot: %s", chroot_dir)

    run_command(["mount", "-t", "proc", "proc", f"{chroot_dir}/proc"])
    run_command(["mount", "-t", "sysfs", "sys", f"{chroot_dir}/sys"])
    run_command(["mount", "--bind", "/dev", f"{chroot_dir}/dev"])
    run_command(["mount", "--bind", "/dev/pts", f"{chroot_dir}/dev/pts"])

    os.makedirs(f"{chroot_dir}/run", exist_ok=True)

    # Set up resolv.conf
    resolv_link = os.path.join(chroot_dir, "etc", "resolv.conf")
    if os.path.islink(resolv_link):
        target = os.readlink(resolv_link)
        if target.startswith("/"):
            target_path = os.path.join(chroot_dir, target.lstrip("/"))
        else:
            target_path = os.path.join(chroot_dir, "etc", target)

        os.makedirs(os.path.dirname(target_path), exist_ok=True)
        shutil.copy("/etc/resolv.conf", target_path)
    else:
        shutil.copy("/etc/resolv.conf", resolv_link)

    LOG.info("Chroot setup complete")
```

</details>

<details>
<summary>teardown_chroot</summary>

Unmounts chroot bind mounts in reverse order.

```python
def teardown_chroot(chroot_dir):
    """Tear down chroot environment.

    :param chroot_dir: Path to chroot directory
    """
    LOG.info("Tearing down chroot: %s", chroot_dir)

    mounts = [
        f"{chroot_dir}/run",
        f"{chroot_dir}/dev/pts",
        f"{chroot_dir}/dev",
        f"{chroot_dir}/sys",
        f"{chroot_dir}/proc",
    ]

    for mount in mounts:
        try:
            result = run_command(["mountpoint", "-q", mount], check=False)
            if result.returncode == 0:
                run_command(["umount", "-l", mount])
        except Exception as e:
            LOG.warning("Error unmounting %s: %s", mount, e)

    LOG.info("Chroot teardown complete")
```

</details>

<details>
<summary>extract_oci_image</summary>

Extracts OCI image filesystem using `crane export` piped to `tar`.

```python
def extract_oci_image(image, platform, dest_dir):
    """Extract OCI image rootfs using crane.

    :param image: OCI image reference (e.g., ubuntu:24.04)
    :param platform: Target platform (e.g., linux/amd64)
    :param dest_dir: Destination directory for rootfs
    """
    LOG.info("Extracting OCI image %s (%s) to %s", image, platform, dest_dir)

    # Use crane export to extract the image filesystem
    # crane export outputs a tar stream, pipe to tar for extraction
    crane_cmd = ["crane", "export", "--platform", platform, image, "-"]
    tar_cmd = ["tar", "-xf", "-", "-C", dest_dir]

    LOG.info("Running: %s | %s", " ".join(crane_cmd), " ".join(tar_cmd))

    # Create pipeline: crane export | tar extract
    crane_proc = subprocess.Popen(
        crane_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )

    tar_proc = subprocess.Popen(
        tar_cmd, stdin=crane_proc.stdout, stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )

    # Allow crane to receive SIGPIPE if tar exits
    crane_proc.stdout.close()

    # Wait for tar to complete
    tar_stdout, tar_stderr = tar_proc.communicate(timeout=1800)

    # Wait for crane to complete
    crane_proc.wait()

    if crane_proc.returncode != 0:
        _, crane_stderr = crane_proc.communicate()
        raise RuntimeError(
            f"crane export failed with code {crane_proc.returncode}: "
            f"{crane_stderr.decode() if crane_stderr else 'unknown error'}"
        )

    if tar_proc.returncode != 0:
        raise RuntimeError(
            f"tar extract failed with code {tar_proc.returncode}: "
            f"{tar_stderr.decode() if tar_stderr else 'unknown error'}"
        )

    if tar_stderr:
        LOG.debug("tar stderr: %s", tar_stderr.decode())

    LOG.info("OCI image extraction complete")
```

</details>

<details>
<summary>install_packages</summary>

Installs cloud-init, GRUB, kernel, and other required packages via apt.

```python
def install_packages(chroot_dir, grub_packages):
    """Install required packages in chroot.

    :param chroot_dir: Path to chroot directory
    :param grub_packages: List of GRUB packages to install
    """
    LOG.info("Installing packages in chroot")

    # Remove snap packages if present
    snap_path = os.path.join(chroot_dir, "usr", "bin", "snap")
    if os.path.exists(snap_path):
        snap_patterns = [
            "!/^Name|^core|^snapd|^lxd/",
            "/^lxd/",
            "/^core/",
            "/^snapd/",
            "!/^Name/",
        ]
        for pattern in snap_patterns:
            try:
                run_command(
                    [
                        "chroot",
                        chroot_dir,
                        "sh",
                        "-c",
                        f"snap list 2&gt;/dev/null | awk '{pattern} ' | "
                        "xargs -rI{} snap remove --purge {}",
                    ],
                    check=False,
                )
            except Exception:
                pass

    # Update package lists
    run_command(["chroot", chroot_dir, "apt-get", "update"])

    # Remove unwanted packages one by one, ignoring errors for missing packages
    for pkg in ["lxd", "lxd-agent-loader", "lxd-installer", "snapd"]:
        run_command(
            ["chroot", chroot_dir, "apt-get", "--purge", "remove", "-y", pkg],
            check=False,
        )

    # Install required packages
    packages = [
        "cloud-init",
        "curl",
        "efibootmgr",
        "grub-common",
        "initramfs-tools",
        "lvm2",
        "mdadm",
        "netplan.io",
        "rsync",
        "sudo",
        "systemd-sysv",
    ] + grub_packages
    run_command(["chroot", chroot_dir, "apt-get", "install", "-y"] + packages)

    # Install kernel based on distro
    try:
        os_release_path = os.path.join(chroot_dir, "etc", "os-release")
        distro_id = None
        version_id = None
        if os.path.exists(os_release_path):
            with open(os_release_path, "r", encoding="utf-8") as f:
                for line in f:
                    if line.startswith("ID="):
                        distro_id = line.split("=")[1].strip().strip('"')
                    elif line.startswith("VERSION_ID="):
                        version_id = line.split("=")[1].strip().strip('"')

        if distro_id == "ubuntu" and version_id:
            # Ubuntu: install HWE kernel
            run_command(
                [
                    "chroot",
                    chroot_dir,
                    "apt-get",
                    "install",
                    "-y",
                    f"linux-generic-hwe-{version_id}",
                ],
                check=False,
            )
        elif distro_id == "debian":
            # Debian: install standard kernel metapackage
            arch = platform.machine()
            if arch == "x86_64":
                kernel_pkg = "linux-image-amd64"
            elif arch == "aarch64":
                kernel_pkg = "linux-image-arm64"
            else:
                kernel_pkg = "linux-image-" + arch
            run_command(
                ["chroot", chroot_dir, "apt-get", "install", "-y", kernel_pkg],
                check=False,
            )
    except Exception as e:
        LOG.warning("Error installing kernel: %s", e)

    # Clean up removed packages
    try:
        result = run_command(["chroot", chroot_dir, "dpkg", "-l"], check=False)
        rc_packages = []
        for line in result.stdout.split("\n"):
            if line.startswith("rc "):
                parts = line.split()
                if len(parts) &gt;= 2:
                    rc_packages.append(parts[1])

        if rc_packages:
            run_command(
                ["chroot", chroot_dir, "apt-get", "purge", "-y"] + rc_packages,
                check=False,
            )
    except Exception:
        pass

    run_command(
        ["chroot", chroot_dir, "apt-get", "autoremove", "--purge", "-y"], check=False
    )

    LOG.info("Package installation complete")
```

</details>

<details>
<summary>write_hosts_file</summary>

Writes `/etc/hosts` with localhost and IPv6 entries.

```python
def write_hosts_file(mount_point, hostname):
    """Write /etc/hosts file with proper entries.

    :param mount_point: Root mount point
    :param hostname: System hostname
    """
    LOG.info("Writing /etc/hosts file")

    hosts_path = os.path.join(mount_point, "etc", "hosts")

    with open(hosts_path, "w", encoding="utf-8") as f:
        f.write(f"127.0.0.1\tlocalhost\t{hostname}\n")
        f.write("\n")
        f.write("# The following lines are desirable for IPv6 capable hosts\n")
        f.write("::1\tip6-localhost\tip6-loopback\n")
        f.write("fe00::0\tip6-localnet\n")
        f.write("ff00::0\tip6-mcastprefix\n")
        f.write("ff02::1\tip6-allnodes\n")
        f.write("ff02::2\tip6-allrouters\n")
        f.write("ff02::3\tip6-allhosts\n")

    LOG.info("/etc/hosts written with hostname: %s", hostname)
```

</details>

<details>
<summary>configure_cloud_init</summary>

Configures cloud-init NoCloud datasource with metadata, userdata, and
network config from configdrive.

```python
def configure_cloud_init(mount_point, configdrive_data):
    """Configure cloud-init with configdrive data.

    :param mount_point: Root mount point
    :param configdrive_data: Configdrive dictionary
    """
    LOG.info("Configuring cloud-init")

    cloud_init_cfg_dir = os.path.join(mount_point, "etc", "cloud", "cloud.cfg.d")
    os.makedirs(cloud_init_cfg_dir, exist_ok=True)

    nocloud_seed_dir = os.path.join(
        mount_point, "var", "lib", "cloud", "seed", "nocloud-net"
    )
    os.makedirs(nocloud_seed_dir, exist_ok=True)

    # Write datasource config
    datasource_cfg = os.path.join(cloud_init_cfg_dir, "99-nocloud-seed.cfg")
    with open(datasource_cfg, "w", encoding="utf-8") as f:
        f.write(
            """datasource_list: [ NoCloud, None ]
datasource:
  NoCloud:
    seedfrom: file:///var/lib/cloud/seed/nocloud-net/
"""
        )

    # Write meta-data
    meta_data = configdrive_data.get("meta_data", {})
    meta_data_path = os.path.join(nocloud_seed_dir, "meta-data")
    with open(meta_data_path, "w", encoding="utf-8") as f:
        yaml.safe_dump(meta_data, f, default_flow_style=False)

    # Write user-data
    user_data = configdrive_data.get("user_data", "")
    user_data_path = os.path.join(nocloud_seed_dir, "user-data")
    with open(user_data_path, "w", encoding="utf-8") as f:
        f.write(user_data if user_data else "")

    # Write network-config if present
    network_data = configdrive_data.get("network_data", {})
    if network_data:
        network_config_path = os.path.join(nocloud_seed_dir, "network-config")
        with open(network_config_path, "w", encoding="utf-8") as f:
            yaml.safe_dump(network_data, f, default_flow_style=False)

    # Set permissions
    for filename in os.listdir(nocloud_seed_dir):
        filepath = os.path.join(nocloud_seed_dir, filename)
        os.chmod(filepath, 0o600)

    LOG.info("Cloud-init configuration complete")
```

</details>

<details>
<summary>write_fstab</summary>

Writes `/etc/fstab` with root and EFI entries, plus second EFI for RAID.

```python
def write_fstab(mount_point, root_label, boot_label, is_raid, boot_label2=None):
    """Write /etc/fstab.

    :param mount_point: Root mount point
    :param root_label: Root partition label
    :param boot_label: EFI partition label
    :param is_raid: Whether RAID is configured
    :param boot_label2: Second EFI partition label
    """
    LOG.info("Writing fstab")

    fstab_path = os.path.join(mount_point, "etc", "fstab")
    with open(fstab_path, "w", encoding="utf-8") as f:
        f.write(f"LABEL={root_label}\t/\text4\terrors=remount-ro\t0\t1\n")
        f.write(f"LABEL={boot_label}\t/boot/efi\tvfat\tumask=0077,nofail\t0\t1\n")

        if is_raid and boot_label2:
            f.write(
                f"LABEL={boot_label2}\t/boot/efi2\tvfat\t"
                f"umask=0077,nofail,noauto\t0\t2\n"
            )

    LOG.info("fstab written")
```

</details>

<details>
<summary>write_mdadm_conf</summary>

Writes `/etc/mdadm/mdadm.conf` with RAID array configuration.

```python
def write_mdadm_conf(mount_point):
    """Write mdadm configuration.

    :param mount_point: Root mount point
    """
    LOG.info("Writing mdadm.conf")

    mdadm_dir = os.path.join(mount_point, "etc", "mdadm")
    os.makedirs(mdadm_dir, exist_ok=True)

    mdadm_conf_path = os.path.join(mdadm_dir, "mdadm.conf")

    with open(mdadm_conf_path, "w", encoding="utf-8") as f:
        f.write("HOMEHOST <system>\n")
        f.write("MAILADDR root\n")

    # Append ARRAY lines from mdadm --detail --scan
    result = run_command(["mdadm", "--detail", "--scan", "--verbose"])
    with open(mdadm_conf_path, "a", encoding="utf-8") as f:
        for line in result.stdout.split("\n"):
            if line.startswith("ARRAY"):
                f.write(line + "\n")

    LOG.info("mdadm.conf written")
```

&lt;/details&gt;

<details>
<summary>configure_initramfs</summary>

Configures initramfs-tools to include LVM and RAID modules.

```python
def configure_initramfs(chroot_dir, is_raid):
    """Configure initramfs-tools for LVM and optionally RAID.

    This ensures initramfs includes LVM modules.

    :param chroot_dir: Chroot directory path
    :param is_raid: Whether RAID is configured
    """
    LOG.info("Configuring initramfs-tools")

    initramfs_conf_dir = os.path.join(chroot_dir, "etc", "initramfs-tools", "conf.d")
    os.makedirs(initramfs_conf_dir, exist_ok=True)

    # Disable resume (no swap partition)
    resume_conf = os.path.join(initramfs_conf_dir, "resume")
    with open(resume_conf, "w", encoding="utf-8") as f:
        f.write("RESUME=none\n")

    # Force LVM inclusion in initramfs
    # This is needed because during chroot, LVM volumes may not be
    # detected by the initramfs-tools hooks
    initramfs_conf = os.path.join(
        chroot_dir, "etc", "initramfs-tools", "initramfs.conf"
    )
    if os.path.exists(initramfs_conf):
        with open(initramfs_conf, "r", encoding="utf-8") as f:
            content = f.read()
        # Set MODULES to "most" to include storage drivers
        content = re.sub(r"^MODULES=.*$", "MODULES=most", content, flags=re.MULTILINE)
        with open(initramfs_conf, "w", encoding="utf-8") as f:
            f.write(content)

    # Add LVM modules explicitly
    modules_file = os.path.join(chroot_dir, "etc", "initramfs-tools", "modules")
    lvm_modules = ["dm-mod", "dm-snapshot", "dm-mirror", "dm-zero"]
    if is_raid:
        lvm_modules.extend(["raid1", "md-mod"])

    existing_modules = set()
    if os.path.exists(modules_file):
        with open(modules_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#"):
                    existing_modules.add(line)

    with open(modules_file, "a", encoding="utf-8") as f:
        for module in lvm_modules:
            if module not in existing_modules:
                f.write(f"{module}\n")

    LOG.info("initramfs-tools configuration complete")
```

</details>

<details>
<summary>setup_grub_defaults</summary>

Configures `/etc/default/grub` with root device and RAID options.

```python
def setup_grub_defaults(chroot_dir, root_label, is_raid):
    """Configure GRUB defaults.

    :param chroot_dir: Chroot directory path
    :param root_label: Root partition label
    :param is_raid: Whether RAID is configured
    """
    LOG.info("Setting up GRUB defaults")

    grub_default = os.path.join(chroot_dir, "etc", "default", "grub")

    with open(grub_default, "r", encoding="utf-8") as f:
        content = f.read()

    # Build GRUB_CMDLINE_LINUX
    cmdline = f"root=LABEL={root_label}"
    if is_raid:
        cmdline += " rd.auto=1"

    # Update GRUB_CMDLINE_LINUX
    content = re.sub(
        r"^#*\s*GRUB_CMDLINE_LINUX=.*$",
        f'GRUB_CMDLINE_LINUX="{cmdline}"',
        content,
        flags=re.MULTILINE,
    )

    # Update GRUB_DISABLE_LINUX_UUID
    if "GRUB_DISABLE_LINUX_UUID=" in content:
        content = re.sub(
            r"^#*\s*GRUB_DISABLE_LINUX_UUID=.*$",
            "GRUB_DISABLE_LINUX_UUID=true",
            content,
            flags=re.MULTILINE,
        )
    else:
        content += "\nGRUB_DISABLE_LINUX_UUID=true\n"

    # Add rootdelay for RAID
    if is_raid:
        if "GRUB_CMDLINE_LINUX_DEFAULT=" in content:
            if "rootdelay=" not in content:
                content = re.sub(
                    r'^(#*\s*GRUB_CMDLINE_LINUX_DEFAULT="[^"]*)',
                    r"\1 rootdelay=10",
                    content,
                    flags=re.MULTILINE,
                )
        else:
            content += '\nGRUB_CMDLINE_LINUX_DEFAULT="rootdelay=10"\n'

    with open(grub_default, "w", encoding="utf-8") as f:
        f.write(content)

    LOG.info("GRUB defaults configured")
```

</details>

<details>
<summary>setup_grub_efi_sync</summary>

Creates GRUB hook script to sync EFI partitions for RAID redundancy.

```python
def setup_grub_efi_sync(chroot_dir, boot_label2):
    """Set up GRUB hook to sync EFI partitions for RAID.

    :param chroot_dir: Chroot directory path
    :param boot_label2: Second EFI partition label
    """
    LOG.info("Setting up GRUB EFI sync hook")

    grub_hook = os.path.join(chroot_dir, "etc", "grub.d", "90_copy_to_boot_efi2")

    with open(grub_hook, "w", encoding="utf-8") as f:
        f.write(
            f"""#!/bin/sh
# Sync GRUB updates to both EFI partitions for RAID redundancy
set -e

if mountpoint --quiet --nofollow /boot/efi; then
    mount LABEL={boot_label2} /boot/efi2 || :
    rsync --times --recursive --delete /boot/efi/ /boot/efi2/
    umount -l /boot/efi2
fi
exit 0
"""
        )

    os.chmod(grub_hook, 0o755)  # nosec B103
    LOG.info("GRUB EFI sync hook created")
```

</details>

<details>
<summary>class DebOCIEFILVMHardwareManager</summary>

Main hardware manager class implementing the `deb_oci_efi_lvm` deploy step.
Orchestrates the full deployment workflow.

```python
class DebOCIEFILVMHardwareManager(hardware.HardwareManager):
    """Hardware manager for OCI EFI LVM RAID deployment."""

    HARDWARE_MANAGER_NAME = "DebOCIEFILVMHardwareManager"
    HARDWARE_MANAGER_VERSION = "1.0"

    def evaluate_hardware_support(self):
        LOG.info("DebOCIEFILVMHardwareManager: " "evaluate_hardware_support called")
        return hardware.HardwareSupport.SERVICE_PROVIDER

    def get_deploy_steps(self, node, ports):
        LOG.info("DebOCIEFILVMHardwareManager: get_deploy_steps called")

        return [
            {
                "step": "deb_oci_efi_lvm",
                "priority": 0,
                "interface": "deploy",
                "reboot_requested": False,
                "argsinfo": {},
            },
        ]

    def deb_oci_efi_lvm(self, node, ports):
        """Deploy Debian-based OCI image with EFI, LVM, and optional RAID.

        :param node: Node dictionary containing deployment configuration
        :param ports: List of port dictionaries for the node
        :raises: ValueError if configuration is invalid
        :raises: RuntimeError if deployment fails
        """
        LOG.info("DebOCIEFILVMHardwareManager: " "deb_oci_efi_lvm called")
        LOG.info("DebOCIEFILVMHardwareManager: node: %s", node)
        LOG.info("DebOCIEFILVMHardwareManager: ports: %s", ports)

        if not is_efi_system():
            raise RuntimeError(
                "This deployment requires EFI boot mode. "
                "System is not booted in EFI mode."
            )

        try:
            # Extract configuration from node
            configdrive_data = get_configdrive_data(node)
            root_device_hints = get_root_device_hints(node, configdrive_data)
            resolved_devices = resolve_root_devices(root_device_hints)
            meta_data = configdrive_data.get("meta_data", {})
            metal3_name = meta_data.get("metal3-name")

            root_device_path = resolved_devices[0]
            second_device = resolved_devices[1] if len(resolved_devices) &gt; 1 else None

            LOG.info(
                "DebOCIEFILVMHardwareManager: " "root_device_path: %s", root_device_path
            )
            if second_device:
                LOG.info(
                    "DebOCIEFILVMHardwareManager: " "second_device: %s (RAID1)",
                    second_device,
                )

            # Get OCI image and architecture-specific configuration
            oci_image = get_oci_image(node, configdrive_data)
            arch_config = get_architecture_config(oci_image)
            LOG.info(
                "DebOCIEFILVMHardwareManager: " "architecture config: %s", arch_config
            )

            # Get disk wipe mode
            is_raid_setup = second_device is not None
            wipe_mode = get_disk_wipe_mode(configdrive_data, is_raid_setup)

            # Clean devices based on wipe mode
            if wipe_mode == "all":
                LOG.info("Cleaning all block devices (wipe_mode: all)")
                clean_all_devices()
                wait_for_device(root_device_path)
                if second_device:
                    wait_for_device(second_device)
            else:  # wipe_mode == 'target'
                LOG.info("Cleaning only target device(s) (wipe_mode: target)")
                wait_for_device(root_device_path)
                clean_device(root_device_path)
                if second_device:
                    wait_for_device(second_device)
                    clean_device(second_device)

            # Partition disk
            is_raid, pv_device = partition_disk(
                root_device_path,
                VG_NAME,
                LV_NAME,
                second_device=second_device,
                raid_device=RAID_DEVICE,
                homehost=metal3_name,
            )

            # Get partition paths
            efi_partition = get_partition_path(root_device_path, 1)
            second_efi_partition = None
            if is_raid and second_device:
                second_efi_partition = get_partition_path(second_device, 1)

            root_lv_path = f"/dev/{VG_NAME}/{LV_NAME}"

            # Create filesystems
            create_filesystems(
                efi_partition,
                root_lv_path,
                boot_label=BOOT_FS_LABEL,
                root_label=ROOT_FS_LABEL,
                second_efi_partition=second_efi_partition,
                boot_label2=BOOT_FS_LABEL2,
            )

            # Mount root filesystem
            root_mount = tempfile.mkdtemp()
            run_command(["mount", root_lv_path, root_mount])

            try:
                # Extract OCI image rootfs
                extract_oci_image(
                    arch_config["oci_image"], arch_config["oci_platform"], root_mount
                )

                # Mount EFI partition
                efi_mount = os.path.join(root_mount, "boot", "efi")
                os.makedirs(efi_mount, exist_ok=True)
                run_command(["mount", efi_partition, efi_mount])

                try:
                    # Set up chroot
                    setup_chroot(root_mount)

                    try:
                        # Install packages
                        install_packages(root_mount, arch_config["grub_packages"])

                        # Configure cloud-init
                        configure_cloud_init(root_mount, configdrive_data)

                        # Write /etc/hosts
                        write_hosts_file(root_mount, metal3_name)

                        # Write fstab
                        write_fstab(
                            root_mount,
                            ROOT_FS_LABEL,
                            BOOT_FS_LABEL,
                            is_raid,
                            BOOT_FS_LABEL2,
                        )

                        # Configure GRUB
                        setup_grub_defaults(root_mount, ROOT_FS_LABEL, is_raid)

                        # RAID-specific configuration
                        if is_raid:
                            write_mdadm_conf(root_mount)
                            setup_grub_efi_sync(root_mount, BOOT_FS_LABEL2)

                            efi2_mount = os.path.join(root_mount, "boot", "efi2")
                            os.makedirs(efi2_mount, exist_ok=True)

                        # Install GRUB to EFI
                        run_command(
                            [
                                "chroot",
                                root_mount,
                                "grub-install",
                                f'--target={arch_config["uefi_target"]}',
                                "--efi-directory=/boot/efi",
                                "--bootloader-id=ubuntu",
                                "--recheck",
                            ]
                        )

                        # Configure initramfs for LVM (required for Debian)
                        configure_initramfs(root_mount, is_raid)

                        # Update GRUB config and initramfs
                        run_command(["chroot", root_mount, "update-grub"])
                        run_command(
                            [
                                "chroot",
                                root_mount,
                                "update-initramfs",
                                "-u",
                                "-k",
                                "all",
                            ]
                        )

                        # Install GRUB to second EFI partition for RAID
                        if is_raid and second_efi_partition:
                            efi2_mount = os.path.join(root_mount, "boot", "efi2")
                            try:
                                run_command(["mount", second_efi_partition, efi2_mount])
                                run_command(
                                    [
                                        "rsync",
                                        "-a",
                                        f"{root_mount}/boot/efi/",
                                        f"{root_mount}/boot/efi2/",
                                    ]
                                )
                                run_command(
                                    [
                                        "chroot",
                                        root_mount,
                                        "grub-install",
                                        f'--target={arch_config["uefi_target"]}',
                                        "--efi-directory=/boot/efi2",
                                        "--bootloader-id=ubuntu",
                                        "--recheck",
                                    ]
                                )
                            except Exception as e:
                                LOG.warning(
                                    "Error installing GRUB to second EFI: %s", e
                                )
                            finally:
                                result = run_command(
                                    ["mountpoint", "-q", efi2_mount], check=False
                                )
                                if result.returncode == 0:
                                    run_command(["umount", "-l", efi2_mount])

                    finally:
                        teardown_chroot(root_mount)

                finally:
                    # Unmount EFI partition
                    result = run_command(["mountpoint", "-q", efi_mount], check=False)
                    if result.returncode == 0:
                        run_command(["umount", "-l", efi_mount])

            finally:
                # Unmount root filesystem
                result = run_command(["mountpoint", "-q", root_mount], check=False)
                if result.returncode == 0:
                    run_command(["umount", "-l", root_mount])

                # Clean up temporary directories
                if root_mount and os.path.exists(root_mount):
                    try:
                        os.rmdir(root_mount)
                        LOG.debug("Cleaned up root mount directory: %s", root_mount)
                    except Exception as e:
                        LOG.warning(
                            "Failed to clean up root mount dir %s: %s", root_mount, e
                        )

            LOG.info(
                "DebOCIEFILVMHardwareManager: " "deb_oci_efi_lvm completed successfully"
            )

        except Exception as e:
            LOG.error("DebOCIEFILVMHardwareManager: " "deb_oci_efi_lvm failed: %s", e)
            raise

        finally:
            # Wait for interactive users to logout
            if has_interactive_users():
                LOG.info(
                    "DebOCIEFILVMHardwareManager: "
                    "interactive users detected, waiting for logout"
                )
                while has_interactive_users():
                    LOG.info(
                        "DebOCIEFILVMHardwareManager: "
                        "users still logged in, checking again "
                        "in 60 seconds"
                    )
                    time.sleep(60)
                LOG.info(
                    "DebOCIEFILVMHardwareManager: " "all interactive users logged out"
                )
```

</details>

<!-- markdownlint-enable MD033 -->

## Supported OCI Images

The hardware manager works with any Debian-based OCI image that has a
functional `apt` package manager. OCI multi-arch images are supported.
Tested images include:

- `ubuntu:24.04`
- `debian:13`

The key benefit of this approach is the ability to create custom OCI
images with your specific OS configuration, packages, and settings.
You can build and maintain your own Docker images and use them directly
as the root filesystem for bare metal deployments. The deployment process
installs additional packages (kernel, GRUB, cloud-init) on top of the
base image.

## Debugging Deployments

If a deployment fails, you can connect to the server via BMC console
during the IPA phase. The hardware manager includes a feature that
waits for interactive users to log out before completing, allowing
you to inspect the system state.

## Limitations and Considerations

The following are limitations of this specific `deb_oci_efi_lvm`
implementation, not of Metal3's custom deploy mechanism itself. The
custom deploy framework is flexible and allows implementing alternative
hardware managers with different capabilities.

1. **EFI only** - This implementation requires UEFI boot mode
1. **Debian-based only** - The package installation assumes `apt` is
   available
1. **Network required** - The IPA needs network access to pull OCI
   images from registries and install packages in target system
1. **Root device hints** - Only `serial` and `wwn` hints are supported
   for disk selection

## Conclusion

The `deb_oci_efi_lvm` hardware manager demonstrates how custom deploy
steps can extend Ironic's capabilities beyond traditional image-based
deployments. The source code and GitHub Actions for building custom IPA
images are available at
[s3rj1k/ironic-python-agent](https://github.com/s3rj1k/ironic-python-agent/tree/custom_deploy).

## Future Improvements

A potential enhancement could add native support for converting OpenStack
`network_data.json` format to cloud-init v1 network configuration during
deployment.

## References

- [Integrating CoreOS Installer with Ironic](https://owlet.today/posts/integrating-coreos-installer-with-ironic/) -
  Dmitry Tantsur's original blog post on custom deploy steps
- [Ironic Deploy Steps Documentation](https://docs.openstack.org/ironic/latest/contributor/deploy-steps.html)
- [Metal3 Custom Deploy Steps Design](https://github.com/metal3-io/metal3-docs/blob/main/design/baremetal-operator/deploy-steps.md)
- [OpenShift CoreOS Install Hardware Manager](https://github.com/openshift/ironic-agent-image/blob/main/hardware_manager/ironic_coreos_install.py)
</system></details></or></in></details>

</article>
<nav class="mk-pagination">
        
          <a class="mk-pagination__page mk-pagination__page--prev" href="/blog/2025/08/27/metal3-becomes-cncf-incubating-project.html" aria-label="previous page">
                <?xml version="1.0" encoding="UTF-8"?>
                <svg enable-background="new 0 0 398.7 320.1" version="1.1" viewBox="0 0 398.7 320.1" xml:space="preserve" xmlns="http://www.w3.org/2000/svg">
                <path d="m199 143.1l136-136c9.4-9.4 24.6-9.4 33.9 0l22.6 22.6c9.4 9.4 9.4 24.6 0 33.9l-96.3 96.5 96.4 96.4c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0l-136-136c-9.5-9.3-9.5-24.6-0.1-33.9zm-192 34l136 136c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-96.3-96.5 96.4-96.4c9.4-9.4 9.4-24.6 0-33.9l-22.6-22.7c-9.4-9.4-24.6-9.4-33.9 0l-136 136c-9.5 9.3-9.5 24.6-0.1 34z"/>
                </svg>
          </a>
        
        
</nav>

        <aside class="mk-blog__categories mk-main__aside">
    <header class="mk-main__header">
            <h2 class="mk-heading mk-heading--xl mk-m-border">Related entries</h2>
    </header>
    <ul class="mk-blog__related-entries">

        
        
        
        
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
              <li class="mk-blog__related-entries__item"><a class="mk-blog__related-entries__link" href="/blog/2024/10/24/Scaling-Kubernetes-with-Metal3-on-Fake-Node.html">Scaling Kubernetes with Metal3: Simulating 1000 Clusters with Fake Ironic Agents</a></li>
              
              
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
              <li class="mk-blog__related-entries__item"><a class="mk-blog__related-entries__link" href="/blog/2019/11/07/Kubernetes-native_Infrastructure-Managed_Baremetal_with_Kubernetes_Operators_and_OpenStack_Ironic.html">Kubernetes-native Infrastructure: Managed Baremetal with Kubernetes Operators and OpenStack Ironic - Steve Hardy, Red Hat</a></li>
              
              
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
          
            
            
            
            
              <li class="mk-blog__related-entries__item"><a class="mk-blog__related-entries__link" href="/blog/2019/05/13/The_new_stack_Metal3_Uses_OpenStack_Ironic_for_Declarative_Bare_Metal_Kubernetes.html">The new stack Metal³ Uses OpenStack's Ironic for Declarative Bare Metal Kubernetes</a></li>
              
              
            
          
            
            
            
            
          
            
            
            
            
              <li class="mk-blog__related-entries__item"><a class="mk-blog__related-entries__link" href="/blog/2019/04/12/Raise_some_horns_Red_Hat_s_MetalKube_aims_to_make_Kubernetes_on_bare_machines_simple.html">Raise some horns, Red Hat's MetalKube aims to make Kubernetes on bare machines simple</a></li>
              
              
                
    </ul>

</aside>

    </main>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
<script src="/assets/js/photoswipe-page.js">
</script>

</main>
<footer class="mk-main-footer">
  <div>
    <div class="mk-cncf-footer">
      <p>We are a <a href="https://cncf.io/">Cloud Native Computing Foundation</a> sandbox project.</p>
      <p><img id= "cncf-image" src="/assets/images/cncf-color.png"/></p>
      <p>Copyright 2026 The Metal³ Contributors - <a href="/privacy-statement.html">Privacy Statement</a></p>
      <p>Copyright 2026 The Linux Foundation. All Rights Reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a> page.</p>
    </div>
      <div class="mk-icons-footer">
        <p>
<!--           <a href="https://twitter.com/metal3_io" aria-label="Visit us on Twitter">
            <i class="fab fa-twitter fa-lg"></i>
          </a> -->
          <a href="https://kubernetes.slack.com/messages/CHD49TLE7" data-placement="top" title="Join our Slack channel">
            <i class="fab fa-slack fa-lg"></i>
          </a>
          <a href="https://github.com/metal3-io" aria-label="View our repo on GitHub">
            <i class="fab fa-github fa-lg"></i>
          </a>
          <a href="https://groups.google.com/g/metal3-dev" aria-label="Send us an email">
            <i class="fas fa-envelope fa-lg"></i>
          </a>
          <a href="https://www.youtube.com/channel/UC_xneeYbo-Dl4g-U78xW15g/videos" aria-label="See our YouTube channel">
            <i class="fab fa-youtube fa-lg"></i>
          </a>
        </p>
      </div>
  </div>
</footer>
</div><!--wrapper-->
<script>
var toggle = document.querySelector('#toggle');
var menu = document.querySelector('#main_nav');
var menuItems = document.querySelectorAll('#main_nav li a');

toggle.addEventListener('click', function(){
if (menu.classList.contains('is-active')) {
  this.setAttribute('aria-expanded', 'false');
  menu.classList.remove('is-active');
} else {
  menu.classList.add('is-active');
  this.setAttribute('aria-expanded', 'true');
  //menuItems[0].focus();
}
});
</script>
    <script src="/assets/js/copy.js"></script>
    <!-- This comes from DTM/DPAL and must be latest entry in body-->
<script>
  let pageLocation = window.location.href
  let footerIcons = document.querySelector(".mk-icons-footer")

  if(pageLocation.includes("community-resources.html")){
    footerIcons.style.display = "none"
  }else {null}

</script>
    <script type="text/javascript">
        if (("undefined" !== typeof _satellite) && ("function" === typeof _satellite.pageBottom)) {
            _satellite.pageBottom();
        }
    </script>
</body>
</html>

